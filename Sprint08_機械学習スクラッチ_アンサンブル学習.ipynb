{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# アンサンブル学習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 小さなデータセットの用意\n",
    ">以前も利用した回帰のデータセットを用意します。\n",
    ">\n",
    ">House Prices: Advanced Regression Techniques\n",
    ">\n",
    ">この中のtrain.csvをダウンロードし、目的変数としてSalePrice、説明変数として、GrLivAreaとYearBuiltを使います。\n",
    ">\n",
    ">train.csvを学習用（train）8割、検証用（val）2割に分割してください。\n",
    ">\n",
    "#### scikit-learn\n",
    ">単一のモデルはスクラッチ実装ではなく、scikit-learnなどのライブラリの使用を推奨します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題1】ブレンディングのスクラッチ実装  \n",
    ">ブレンディング をスクラッチ実装し、単一モデルより精度があがる例を 最低3つ 示してください。精度があがるとは、検証用データに対する平均二乗誤差（MSE）が小さくなることを指します。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ブレンディングとは\n",
    ">ブレンディングとは、N個の多様なモデルを独立して学習させ、推定結果を重み付けした上で足し合わせる方法です。最も単純には平均をとります。多様なモデルとは、以下のような条件を変化させることで作り出すものです。\n",
    ">\n",
    ">- 手法（例：線形回帰、SVM、決定木、ニューラルネットワークなど）\n",
    ">- ハイパーパラメータ（例：SVMのカーネルの種類、重みの初期値など）\n",
    ">- 入力データの前処理の仕方（例：標準化、対数変換、PCAなど）\n",
    ">\n",
    ">重要なのはそれぞれのモデルが大きく異なることです。\n",
    ">\n",
    ">回帰問題でのブレンディングは非常に単純であるため、scikit-learnには用意されていません。\n",
    ">\n",
    ">《補足》\n",
    ">\n",
    ">分類問題の場合は、多数決を行います。回帰問題に比べると複雑なため、scikit-learnにはVotingClassifierが用意されています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1710</td>\n",
       "      <td>2003</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1262</td>\n",
       "      <td>1976</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1786</td>\n",
       "      <td>2001</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1717</td>\n",
       "      <td>1915</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2198</td>\n",
       "      <td>2000</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>1647</td>\n",
       "      <td>1999</td>\n",
       "      <td>175000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>2073</td>\n",
       "      <td>1978</td>\n",
       "      <td>210000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>2340</td>\n",
       "      <td>1941</td>\n",
       "      <td>266500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>1078</td>\n",
       "      <td>1950</td>\n",
       "      <td>142125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>1256</td>\n",
       "      <td>1965</td>\n",
       "      <td>147500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1460 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      GrLivArea  YearBuilt  SalePrice\n",
       "0          1710       2003     208500\n",
       "1          1262       1976     181500\n",
       "2          1786       2001     223500\n",
       "3          1717       1915     140000\n",
       "4          2198       2000     250000\n",
       "...         ...        ...        ...\n",
       "1455       1647       1999     175000\n",
       "1456       2073       1978     210000\n",
       "1457       2340       1941     266500\n",
       "1458       1078       1950     142125\n",
       "1459       1256       1965     147500\n",
       "\n",
       "[1460 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# データセットcsvをpandasに読み込む\n",
    "\n",
    "csv_path = \"./Kaggle_data/train.csv\" # ファイル名（パス）を指定する\n",
    "df_data = pd.read_csv(csv_path)\n",
    "\n",
    "# 条件に従って抜き出し\n",
    "df_X = df_data[['GrLivArea', 'YearBuilt']]\n",
    "df_y = df_data['SalePrice']\n",
    "\n",
    "df = pd.concat([df_X, df_y], axis=1)\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1710 2003]\n",
      " [1262 1976]\n",
      " [1786 2001]\n",
      " ...\n",
      " [2340 1941]\n",
      " [1078 1950]\n",
      " [1256 1965]]\n",
      "[208500 181500 223500 ... 266500 142125 147500]\n"
     ]
    }
   ],
   "source": [
    "# 特徴量（説明変数）をX、正解（目的変数）をyというndarrayに格納\n",
    "\n",
    "X = np.array(df[['GrLivArea','YearBuilt']])\n",
    "y = np.array(df['SalePrice'])\n",
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1168, 2)\n",
      "(1168,)\n",
      "(292, 2)\n",
      "(292,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "#from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "#from sklearn.svm import SVC\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "#from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "今回のベースライン\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>平均二乗誤差（MSE）</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>k-nearest neighbors</td>\n",
       "      <td>2.138338e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>2.942067e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM</td>\n",
       "      <td>7.221625e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>3.157409e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model   平均二乗誤差（MSE）\n",
       "0  k-nearest neighbors  2.138338e+09\n",
       "1     LinearRegression  2.942067e+09\n",
       "2                  SVM  7.221625e+09\n",
       "3         DecisionTree  3.157409e+09"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 精度の一覧表用の空のリストを用意\n",
    "verification_result = []\n",
    "\n",
    "\n",
    "#最近傍法\n",
    "verification_neigh = ['k-nearest neighbors']\n",
    "\n",
    "# 近傍点を５に設定して学習\n",
    "neigh_baseline = KNeighborsRegressor(n_neighbors=5)# インスタンス化\n",
    "neigh_baseline.fit(X_train_scaled, y_train)# 学習\n",
    "y_pred_n = neigh_baseline.predict(X_test_scaled)# 予測\n",
    "\n",
    "# 平均二乗誤差（Mean Squared Error, MSE）    \n",
    "verification_neigh.append(mean_squared_error(y_test,  y_pred_n))\n",
    "\n",
    "\n",
    "# 線形回帰\n",
    "verification_linear = ['LinearRegression']\n",
    "\n",
    "linear_baseline = LinearRegression()\n",
    "linear_baseline.fit(X_train_scaled, y_train)\n",
    "y_pred_li = linear_baseline.predict(X_test_scaled)\n",
    "\n",
    "# 平均二乗誤差（Mean Squared Error, MSE）    \n",
    "verification_linear.append(mean_squared_error(y_test,  y_pred_li))\n",
    "\n",
    "\n",
    "\n",
    "# SVM\n",
    "verification_svm = ['SVM']\n",
    "\n",
    "svm_baseline = SVR()\n",
    "svm_baseline.fit(X_train_scaled, y_train)\n",
    "y_pred_s = svm_baseline.predict(X_test_scaled)\n",
    "\n",
    "# 平均二乗誤差（Mean Squared Error, MSE）\n",
    "verification_svm.append(mean_squared_error(y_test, y_pred_s))\n",
    "\n",
    "\n",
    "\n",
    "# 決定木\n",
    "verification_tree = ['DecisionTree']\n",
    "\n",
    "tree_baseline = DecisionTreeRegressor()\n",
    "tree_baseline.fit(X_train_scaled, y_train)\n",
    "y_pred_t = tree_baseline.predict(X_test_scaled)\n",
    "\n",
    "# 平均二乗誤差（Mean Squared Error, MSE）\n",
    "verification_tree.append(mean_squared_error(y_test, y_pred_t))\n",
    "\n",
    "\n",
    "\n",
    "# 表を作成するために計算結果を２次元配列にする\n",
    "verification_result = [\n",
    "            verification_neigh,\n",
    "            verification_linear, \n",
    "            verification_svm, \n",
    "            verification_tree, \n",
    "        ]\n",
    "\n",
    "\n",
    "# 行と列のインデックスようのリストを用意\n",
    "data_columns=['Model', '平均二乗誤差（MSE）']\n",
    "\n",
    "# pandas のデータフレームにする\n",
    "df_verification = pd.DataFrame(data=verification_result, columns=data_columns)\n",
    "\n",
    "print(\"今回のベースライン\")\n",
    "display(df_verification)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最近傍法、線形回帰、決定木、SVMの順に精度が高い。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScratchEnsembleLearning():\n",
    "    \"\"\"\n",
    "    アンサンブル学習\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    verbose : bool\n",
    "      学習過程を出力する場合はTrue\n",
    "      \n",
    "    Attributes\n",
    "    ----------\n",
    "    \"\"\"\n",
    "    def __init__(self, verbose=False):\n",
    "        # ハイパーパラメータを属性として記録\n",
    "        self.verbose = verbose\n",
    "        \n",
    "        \n",
    "    def fit(self, X, y, model_instance, weight):\n",
    "        \"\"\"\n",
    "        学習する\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            訓練データの特徴量\n",
    "        y : 次の形のndarray, shape (n_samples, )\n",
    "            訓練データの正解値\n",
    "        \"\"\"\n",
    "        INSTANCE_0 = model_instance[0]\n",
    "        INSTANCE_1 = model_instance[1]\n",
    "        INSTANCE_2 = model_instance[2]\n",
    "\n",
    "        INSTANCE_0.fit(X, y)\n",
    "        INSTANCE_1.fit(X, y)\n",
    "        INSTANCE_2.fit(X, y)\n",
    "        \n",
    "        self.instance_0 = INSTANCE_0\n",
    "        self.instance_1 = INSTANCE_1\n",
    "        self.instance_2 = INSTANCE_2\n",
    "        \n",
    "        \n",
    "    def predict(self, X_test):\n",
    "        \"\"\"\n",
    "        推定する\n",
    "        \"\"\"\n",
    "        pred_0 = self.instance_0.predict(X_test)\n",
    "        pred_1 = self.instance_1.predict(X_test)\n",
    "        pred_2 = self.instance_2.predict(X_test)\n",
    "        \n",
    "        pred = (pred_0*weight[0] + pred_1*weight[1] + pred_2*weight[2])#/3\n",
    "        \n",
    "        self.pred = pred\n",
    "        self.pred_0 = pred_0\n",
    "        self.pred_1 = pred_1\n",
    "        self.pred_2 = pred_2\n",
    "        \n",
    "        return pred\n",
    "    \n",
    "    \n",
    "    def MSE(self, y_test, y_pred):\n",
    "        \"\"\"\n",
    "        平均二乗誤差（Mean Squared Error, MSE）\n",
    "        \"\"\"\n",
    "        MSE = mean_squared_error(y_test, y_pred)\n",
    "        \n",
    "        # 精度の一覧表用の空のリストを用意\n",
    "        verification_result = []\n",
    "        MSE_0 = mean_squared_error(y_test, self.pred_0)\n",
    "        MSE_1 = mean_squared_error(y_test, self.pred_1)\n",
    "        MSE_2 = mean_squared_error(y_test, self.pred_2)\n",
    "        \n",
    "        # 表を作成するために計算結果を２次元配列にする\n",
    "        verification_MSE_0 = ['INSTANCE_0', MSE_0]\n",
    "        verification_MSE_1 = ['INSTANCE_1', MSE_1]\n",
    "        verification_MSE_2 = ['INSTANCE_2', MSE_2]\n",
    "        verification_MSE = ['EnsembleLearning', MSE]\n",
    "        verification_result = [\n",
    "                    verification_MSE_0, \n",
    "                    verification_MSE_1, \n",
    "                    verification_MSE_2, \n",
    "                    verification_MSE\n",
    "                ]\n",
    "        # pandas のデータフレームにする\n",
    "        df_verification = pd.DataFrame(data=verification_result, columns=data_columns)\n",
    "        display(df_verification)\n",
    "        \n",
    "        return MSE\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# インスタンス化\n",
    "neigh = KNeighborsRegressor(n_neighbors=5)\n",
    "linear = LinearRegression()\n",
    "svm = SVR()\n",
    "tree = DecisionTreeRegressor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### パターン１  \n",
    "ベースラインが良かったもの３つを均等な比率で組み合わせる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>平均二乗誤差（MSE）</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INSTANCE_0</td>\n",
       "      <td>2.138338e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INSTANCE_1</td>\n",
       "      <td>2.942067e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INSTANCE_2</td>\n",
       "      <td>3.194443e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EnsembleLearning</td>\n",
       "      <td>2.292421e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Model   平均二乗誤差（MSE）\n",
       "0        INSTANCE_0  2.138338e+09\n",
       "1        INSTANCE_1  2.942067e+09\n",
       "2        INSTANCE_2  3.194443e+09\n",
       "3  EnsembleLearning  2.292421e+09"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2292421141.83418"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 引数\n",
    "model_instance = [neigh, linear, tree]\n",
    "weight = [0.34, 0.33, 0.33]\n",
    "\n",
    "# インスタンス化\n",
    "ensemble_learning_1 = ScratchEnsembleLearning()\n",
    "ensemble_learning_1.fit(X_train_scaled, y_train, model_instance, weight)\n",
    "y_pred = ensemble_learning_1.predict(X_test_scaled)\n",
    "ensemble_learning_1.MSE(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "精度が低い決定木に引っ張られて全体的に精度が下がった。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### パターン２  \n",
    "最近傍法がさらに強く出るように比率を変更。また、決定木は誤差が大きいのであまり効かないよう重みを下げた。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>平均二乗誤差（MSE）</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INSTANCE_0</td>\n",
       "      <td>2.138338e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INSTANCE_1</td>\n",
       "      <td>2.942067e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INSTANCE_2</td>\n",
       "      <td>3.121344e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EnsembleLearning</td>\n",
       "      <td>2.139811e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Model   平均二乗誤差（MSE）\n",
       "0        INSTANCE_0  2.138338e+09\n",
       "1        INSTANCE_1  2.942067e+09\n",
       "2        INSTANCE_2  3.121344e+09\n",
       "3  EnsembleLearning  2.139811e+09"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2139811438.859748"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 引数\n",
    "model_instance = [neigh, linear, tree]\n",
    "weight = [0.7, 0.2, 0.1]\n",
    "\n",
    "# インスタンス化\n",
    "ensemble_learning_2 = ScratchEnsembleLearning()\n",
    "ensemble_learning_2.fit(X_train_scaled, y_train, model_instance, weight)\n",
    "y_pred = ensemble_learning_2.predict(X_test_scaled)\n",
    "ensemble_learning_2.MSE(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "精度は上がったが、まだ最近傍法のベースラインよりは誤差が大きい状況。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### パターン3  \n",
    "最近傍法が精度が高いのでさらに比率を上げて実行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>平均二乗誤差（MSE）</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INSTANCE_0</td>\n",
       "      <td>2.138338e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INSTANCE_1</td>\n",
       "      <td>2.942067e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INSTANCE_2</td>\n",
       "      <td>3.316931e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EnsembleLearning</td>\n",
       "      <td>2.141752e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Model   平均二乗誤差（MSE）\n",
       "0        INSTANCE_0  2.138338e+09\n",
       "1        INSTANCE_1  2.942067e+09\n",
       "2        INSTANCE_2  3.316931e+09\n",
       "3  EnsembleLearning  2.141752e+09"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2141751678.838851"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 引数\n",
    "model_instance = [neigh, linear, tree]\n",
    "weight = [0.8, 0.1, 0.1]\n",
    "\n",
    "# インスタンス化\n",
    "ensemble_learning_4 = ScratchEnsembleLearning()\n",
    "ensemble_learning_4.fit(X_train_scaled, y_train, model_instance, weight)\n",
    "y_pred = ensemble_learning_4.predict(X_test_scaled)\n",
    "ensemble_learning_4.MSE(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "かなりベースラインの精度に近づいてきたことを確認。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### パターン４ \n",
    "これまで使用していた中で最も精度が低い決定木をSVMに変更。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>平均二乗誤差（MSE）</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INSTANCE_0</td>\n",
       "      <td>2.138338e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INSTANCE_1</td>\n",
       "      <td>2.942067e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INSTANCE_2</td>\n",
       "      <td>7.221625e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EnsembleLearning</td>\n",
       "      <td>2.190372e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Model   平均二乗誤差（MSE）\n",
       "0        INSTANCE_0  2.138338e+09\n",
       "1        INSTANCE_1  2.942067e+09\n",
       "2        INSTANCE_2  7.221625e+09\n",
       "3  EnsembleLearning  2.190372e+09"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2190372216.170055"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 引数\n",
    "model_instance = [neigh, linear, svm]\n",
    "weight = [0.8, 0.1, 0.1]\n",
    "\n",
    "# インスタンス化\n",
    "ensemble_learning_3 = ScratchEnsembleLearning()\n",
    "ensemble_learning_3.fit(X_train_scaled, y_train, model_instance, weight)\n",
    "y_pred = ensemble_learning_3.predict(X_test_scaled)\n",
    "ensemble_learning_3.MSE(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "やや精度が下がった。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### パターン５\n",
    "線形回帰をSVMに変更。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>平均二乗誤差（MSE）</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INSTANCE_0</td>\n",
       "      <td>2.138338e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INSTANCE_1</td>\n",
       "      <td>7.221625e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INSTANCE_2</td>\n",
       "      <td>3.338991e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EnsembleLearning</td>\n",
       "      <td>2.149598e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Model   平均二乗誤差（MSE）\n",
       "0        INSTANCE_0  2.138338e+09\n",
       "1        INSTANCE_1  7.221625e+09\n",
       "2        INSTANCE_2  3.338991e+09\n",
       "3  EnsembleLearning  2.149598e+09"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2149597785.5427303"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 引数\n",
    "model_instance = [neigh, svm, tree]\n",
    "weight = [0.8, 0.1, 0.1]\n",
    "\n",
    "# インスタンス化\n",
    "ensemble_learning_3 = ScratchEnsembleLearning()\n",
    "ensemble_learning_3.fit(X_train_scaled, y_train, model_instance, weight)\n",
    "y_pred = ensemble_learning_3.predict(X_test_scaled)\n",
    "ensemble_learning_3.MSE(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ベースラインよりも精度が高いモデルを作ることができた。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 結論  \n",
    "最近傍法, SVM, 決定木を0.8, 0.1, 0.1の重みづけで出力すると一番誤差が少なく、  \n",
    "ベースラインよりも精度が上がることが分かった。  \n",
    "個別で精度が高いモデルの比率が高い方がいい結果が出やすいことがわかった。  \n",
    "一方で、個別で精度が低いモデルと入れ替えてみると組み合わせがうまくいったのか、  \n",
    "全体の精度を引き上げることがあるということが分かった。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題2】バギングのスクラッチ実装  \n",
    ">バギング をスクラッチ実装し、単一モデルより精度があがる例を 最低1つ 示してください。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## バギングとは  \n",
    ">バギングは入力データの選び方を多様化する方法です。学習データから重複を許した上でランダムに抜き出すことで、N種類のサブセット（ **ブートストラップサンプル** ）を作り出します。それらによってモデルをN個学習し、推定結果の平均をとります。ブレンディングと異なり、それぞれの重み付けを変えることはありません。\n",
    ">\n",
    ">sklearn.model_selection.train_test_split — scikit-learn 0.21.3 documentation\n",
    ">\n",
    ">scikit-learnのtrain_test_splitを、shuffleパラメータをTrueにして使うことで、ランダムにデータを分割することができます。これによりブートストラップサンプルが手に入ります。\n",
    ">\n",
    ">推定結果の平均をとる部分はブースティングと同様の実装になります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "class ScratchBagging():\n",
    "    \"\"\"\n",
    "    バギング\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    verbose : bool\n",
    "      学習過程を出力する場合はTrue\n",
    "      \n",
    "    Attributes\n",
    "    ----------\n",
    "    \"\"\"\n",
    "    def __init__(self, verbose=False):\n",
    "        # ハイパーパラメータを属性として記録\n",
    "        self.verbose = verbose\n",
    "        \n",
    "        \n",
    "    def fit(self, X, y, model_instance, test_size=0.2):\n",
    "        \"\"\"\n",
    "        学習する\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            訓練データの特徴量\n",
    "        y : 次の形のndarray, shape (n_samples, )\n",
    "            訓練データの正解値\n",
    "        \"\"\"\n",
    "        X_train_0, _ , y_train_0, _ = train_test_split(X, y, test_size=test_size, shuffle=True)\n",
    "        X_train_1, _ , y_train_1, _ = train_test_split(X, y, test_size=test_size, shuffle=True)  \n",
    "        X_train_2, _ , y_train_2, _ = train_test_split(X, y, test_size=test_size, shuffle=True)\n",
    "        \n",
    "        model_0 = model_instance[0]\n",
    "        model_1 = model_instance[1]\n",
    "        model_2 = model_instance[2]\n",
    "        \n",
    "        model_0.fit(X_train_0, y_train_0)\n",
    "        model_1.fit(X_train_1, y_train_1)\n",
    "        model_2.fit(X_train_2, y_train_2)\n",
    "        \n",
    "        self.instance_0 = model_0\n",
    "        self.instance_1 = model_1\n",
    "        self.instance_2 = model_2\n",
    "        \n",
    "        \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        推定する\n",
    "        \"\"\"\n",
    "        pred_tmp_0 = self.instance_0.predict(X)\n",
    "        pred_tmp_1 = self.instance_1.predict(X)\n",
    "        pred_tmp_2 = self.instance_2.predict(X)\n",
    "        \n",
    "        pred = (pred_tmp_0+pred_tmp_1+pred_tmp_2)/3\n",
    "        \n",
    "        self.pred_0 = pred_tmp_0\n",
    "        self.pred_1 = pred_tmp_1\n",
    "        self.pred_2 = pred_tmp_2\n",
    "        \n",
    "        return pred\n",
    "    \n",
    "    \n",
    "    def MSE(self, y_test, y_pred):\n",
    "        \"\"\"\n",
    "        平均二乗誤差（Mean Squared Error, MSE）\n",
    "        \"\"\"\n",
    "        MSE = mean_squared_error(y_test, y_pred)\n",
    "        \n",
    "        # 精度の一覧表用の空のリストを用意\n",
    "        verification_result = []\n",
    "        MSE_0 = mean_squared_error(y_test, self.pred_0)\n",
    "        MSE_1 = mean_squared_error(y_test, self.pred_1)\n",
    "        MSE_2 = mean_squared_error(y_test, self.pred_2)\n",
    "        \n",
    "        # 表を作成するために計算結果を２次元配列にする\n",
    "        verification_MSE_0 = ['INSTANCE_0', MSE_0]\n",
    "        verification_MSE_1 = ['INSTANCE_1', MSE_1]\n",
    "        verification_MSE_2 = ['INSTANCE_3', MSE_2]\n",
    "        verification_MSE = ['Bagging', MSE]\n",
    "        verification_result = [\n",
    "                    verification_MSE_0, \n",
    "                    verification_MSE_1, \n",
    "                    verification_MSE_2, \n",
    "                    verification_MSE\n",
    "                ]\n",
    "        # pandas のデータフレームにする\n",
    "        df_verification = pd.DataFrame(data=verification_result, columns=data_columns)\n",
    "        display(df_verification)\n",
    "        \n",
    "        return MSE\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### パターン1\n",
    "ベースラインの結果が良かった最近傍法で実施。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>平均二乗誤差（MSE）</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INSTANCE_0</td>\n",
       "      <td>2.110598e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INSTANCE_1</td>\n",
       "      <td>2.015035e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INSTANCE_3</td>\n",
       "      <td>2.048022e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bagging</td>\n",
       "      <td>2.011157e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Model   平均二乗誤差（MSE）\n",
       "0  INSTANCE_0  2.110598e+09\n",
       "1  INSTANCE_1  2.015035e+09\n",
       "2  INSTANCE_3  2.048022e+09\n",
       "3     Bagging  2.011157e+09"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2011157381.2615824"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 引数\n",
    "svm_bagging_0 = KNeighborsRegressor(n_neighbors=5)\n",
    "svm_bagging_1 = KNeighborsRegressor(n_neighbors=5)\n",
    "svm_bagging_2 = KNeighborsRegressor(n_neighbors=5)\n",
    "\n",
    "model_instance = [svm_bagging_0, svm_bagging_1, svm_bagging_2]\n",
    "\n",
    "# インスタンス化\n",
    "bagging_1 = ScratchBagging()\n",
    "bagging_1.fit(X_train_scaled, y_train, model_instance, test_size=0.2)\n",
    "y_pred_b = bagging_1.predict(X_test_scaled)\n",
    "bagging_1.MSE(y_test, y_pred_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### パターン２\n",
    "ベースライン２番目に良かった線形回帰で実施。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>平均二乗誤差（MSE）</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INSTANCE_0</td>\n",
       "      <td>2.988697e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INSTANCE_1</td>\n",
       "      <td>2.958038e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INSTANCE_3</td>\n",
       "      <td>2.903096e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bagging</td>\n",
       "      <td>2.945249e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Model   平均二乗誤差（MSE）\n",
       "0  INSTANCE_0  2.988697e+09\n",
       "1  INSTANCE_1  2.958038e+09\n",
       "2  INSTANCE_3  2.903096e+09\n",
       "3     Bagging  2.945249e+09"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2945249416.5680766"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 引数\n",
    "linear_bagging_0 = LinearRegression()\n",
    "linear_bagging_1 = LinearRegression()\n",
    "linear_bagging_2 = LinearRegression()\n",
    "\n",
    "model_instance = [linear_bagging_0, linear_bagging_1, linear_bagging_2]\n",
    "\n",
    "# インスタンス化\n",
    "bagging_1 = ScratchBagging()\n",
    "bagging_1.fit(X_train_scaled, y_train, model_instance, test_size=0.2)\n",
    "y_pred_b = bagging_1.predict(X_test_scaled)\n",
    "bagging_1.MSE(y_test, y_pred_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### パターン３\n",
    "３番目に精度が高かった決定木で実施。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>平均二乗誤差（MSE）</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INSTANCE_0</td>\n",
       "      <td>3.526428e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INSTANCE_1</td>\n",
       "      <td>3.063766e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INSTANCE_3</td>\n",
       "      <td>3.692474e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bagging</td>\n",
       "      <td>2.701435e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Model   平均二乗誤差（MSE）\n",
       "0  INSTANCE_0  3.526428e+09\n",
       "1  INSTANCE_1  3.063766e+09\n",
       "2  INSTANCE_3  3.692474e+09\n",
       "3     Bagging  2.701435e+09"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2701435297.8975983"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 引数\n",
    "tree_bagging_0 = DecisionTreeRegressor()\n",
    "tree_bagging_1 = DecisionTreeRegressor()\n",
    "tree_bagging_2 = DecisionTreeRegressor()\n",
    "\n",
    "model_instance = [tree_bagging_0, tree_bagging_1, tree_bagging_2]\n",
    "\n",
    "# インスタンス化\n",
    "bagging_1 = ScratchBagging()\n",
    "bagging_1.fit(X_train_scaled, y_train, model_instance, test_size=0.2)\n",
    "y_pred_b = bagging_1.predict(X_test_scaled)\n",
    "bagging_1.MSE(y_test, y_pred_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### パターン４\n",
    "ベースラインがよくなかったSVMで実施。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>平均二乗誤差（MSE）</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INSTANCE_0</td>\n",
       "      <td>7.183578e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INSTANCE_1</td>\n",
       "      <td>7.354046e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INSTANCE_3</td>\n",
       "      <td>7.186242e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bagging</td>\n",
       "      <td>7.237039e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Model   平均二乗誤差（MSE）\n",
       "0  INSTANCE_0  7.183578e+09\n",
       "1  INSTANCE_1  7.354046e+09\n",
       "2  INSTANCE_3  7.186242e+09\n",
       "3     Bagging  7.237039e+09"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "7237039467.082136"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 引数\n",
    "neigh_bagging_0 = SVR()\n",
    "neigh_bagging_1 = SVR()\n",
    "neigh_bagging_2 = SVR()\n",
    "\n",
    "model_instance = [neigh_bagging_0, neigh_bagging_1, neigh_bagging_2]\n",
    "\n",
    "# インスタンス化\n",
    "bagging_1 = ScratchBagging()\n",
    "bagging_1.fit(X_train_scaled, y_train, model_instance, test_size=0.2)\n",
    "y_pred_b = bagging_1.predict(X_test_scaled)\n",
    "bagging_1.MSE(y_test, y_pred_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 結論  \n",
    "最近傍法, 決定木はバギングによって精度が向上した。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題3】スタッキングのスクラッチ実装  \n",
    ">スタッキング をスクラッチ実装し、単一モデルより精度があがる例を 最低1つ 示してください。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScratchStacking():\n",
    "    \"\"\"\n",
    "    スタッキング\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    verbose : bool\n",
    "      学習過程を出力する場合はTrue\n",
    "      \n",
    "    Attributes\n",
    "    ----------\n",
    "    self.pred_list\n",
    "    　　\n",
    "    self.instance_list\n",
    "    　　\n",
    "    self.instance_l2\n",
    "      \n",
    "    \"\"\"\n",
    "    def __init__(self, verbose=False):\n",
    "        # ハイパーパラメータを属性として記録\n",
    "        self.verbose = verbose\n",
    "        \n",
    "        \n",
    "    def fit(self, X, y, INSTANCE, INSTANCE_L2):\n",
    "        \"\"\"\n",
    "        学習する\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            訓練データの特徴量\n",
    "        y : 次の形のndarray, shape (n_samples, )\n",
    "            訓練データの正解値\n",
    "        \"\"\"\n",
    "        ############ ステージ０　############\n",
    "        # 推定保管用\n",
    "        pred_list = []\n",
    "        \n",
    "        # モデル数分ループ\n",
    "        for i in range(3):\n",
    "            # データを４分割\n",
    "            kf = KFold(n_splits=4)\n",
    "            # データ分割を実施\n",
    "            kf.get_n_splits(X)\n",
    "            \n",
    "            # 推定保管用\n",
    "            pred_tmp = []\n",
    "            \n",
    "            # ループ回数のカウント用\n",
    "            j = 0\n",
    "            #for j, (train_index, test_index) in enumerate(zip(kf.split(X))):\n",
    "            for train_index, test_index in kf.split(X):\n",
    "                X_train, X_test = X[train_index], X[test_index]\n",
    "                y_train, y_test = y[train_index], y[test_index]\n",
    "                \n",
    "                # 学習\n",
    "                INSTANCE[i][j].fit(X_train, y_train)\n",
    "                # 推定\n",
    "                y_pred = INSTANCE[i][j].predict(X_test)\n",
    "                pred_tmp.extend(y_pred)\n",
    "                \n",
    "                j += 1\n",
    "            \n",
    "            # OOF\n",
    "            pred_list.append(pred_tmp)\n",
    "\n",
    "        # OOF の保管\n",
    "        self.pred_list = np.array(pred_list).T\n",
    "        # インスタンスの保管\n",
    "        self.instance_list = np.array(INSTANCE)\n",
    "        \n",
    "        ############ ステージN　############\n",
    "        # pred を 学習用に分割\n",
    "        X_train_l2, X_test_l2, y_train_l2, y_test_l2 = train_test_split(self.pred_list, y, test_size=0.2, random_state=0)\n",
    "\n",
    "        # 学習\n",
    "        INSTANCE_L2.fit(X_train_l2, y_train_l2)\n",
    "        # インスタンスの保管\n",
    "        self.instance_l2 = INSTANCE_L2\n",
    "        \n",
    "        \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        推定する\n",
    "        \"\"\"\n",
    "        ############ ステージ０　############\n",
    "        # 推定保管用\n",
    "        pred_list = []\n",
    "        for i in range(3):\n",
    "            # 推定保管用\n",
    "            pred_tmp = []\n",
    "            for j in range(4):\n",
    "                # 推定\n",
    "                y_pred = self.instance_list[i, j].predict(X)\n",
    "                pred_tmp.append(y_pred)\n",
    "            # 同一モデルないで平均を取る\n",
    "            pred_tmp = np.mean(np.array(pred_tmp).T, axis=1)\n",
    "            pred_list.append(pred_tmp)\n",
    "            \n",
    "        # 推定データの作成\n",
    "        pred_list = np.array(pred_list).T\n",
    "        \n",
    "        ############ ステージN　############\n",
    "        y_pred_l2 = self.instance_l2.predict(pred_list)\n",
    "        print(y_pred_l2)\n",
    "        \n",
    "        return y_pred_l2\n",
    "    \n",
    "    \n",
    "    def MSE(self, y_test, y_pred):\n",
    "        \"\"\"\n",
    "        平均二乗誤差（Mean Squared Error, MSE）\n",
    "        \"\"\"\n",
    "        MSE = mean_squared_error(y_test, y_pred)\n",
    "        \n",
    "        return MSE\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### パターン1\n",
    "ベースラインとして単独で実施したときに最も精度の良かったSVCのみで構成して実施。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[227577.  135860.  130300.  182580.  122305.   83540.  227577.  125280.\n",
      " 416557.4 151800.  208780.  168080.  229386.4 140080.  137080.  153800.\n",
      " 224033.  142100.  151780.  140760.  152200.  139100.  119770.  167920.\n",
      " 198069.  124500.  248795.6 117700.  269824.2 134900.  197609.  210800.\n",
      " 131780.  259383.4 358433.6 168149.6 211400.  118400.  285259.6 290704.6\n",
      " 227880.  161700.  218477.  306701.8 399943.4 166800.  136380.  141560.\n",
      " 188320.  111076.6 493854.  141290.  151800.   97551.2 213600.  122200.\n",
      " 123770.  266840.  139300.  112760.  152140.  154180.  153067.4 182740.\n",
      " 203480.  166700.  112700.  290704.6 109900.  222200.  171440.  103158.6\n",
      " 120600.  166269.  112700.  302001.8 126280.  112760.  323180.  164720.\n",
      " 133210.  138140.  124920.  142100.  284359.8 170520.  101280.  208200.\n",
      " 178680.  159300.  215839.  188580.  211392.6 258640.  190220.  134500.\n",
      " 200520.  146800.  121200.  154400.  235338.  229265.6 134580.  182060.\n",
      "  84480.  322800.  174860.  101600.  211560.  123600.  101460.  131700.\n",
      " 200056.  109900.  159472.8 196600.  314183.8 135900.  217394.  290704.6\n",
      " 151800.  167920.  147270.  204500.  202480.  233080.  358433.6 190908.\n",
      " 150700.  174740.  174626.6 151472.8 249013.  163380.  121200.  215839.\n",
      " 141390.  178360.   96580.  167920.  123770.  165200.  222900.  136700.\n",
      " 131350.  159659.6 195600.  136740.  282922.6 196600.  150380.  290704.6\n",
      " 249013.  180650.  150000.  229265.6 109900.  158000.  145400.  188580.\n",
      " 122200.  162700.  229415.6 132660.  229415.6 154400.  152200.  269824.2\n",
      " 238900.  250060.  150486.8 159000.  180088.  168680.  137080.  104100.\n",
      " 133390.  266840.  119500.  136700.  235600.  174626.6 111500.  269824.2\n",
      "  84300.  184000.  131952.  150700.  165600.  139100.  142100.  138380.\n",
      " 234800.  153780.  109900.  159300.  117700.  150190.  147600.  167780.\n",
      " 143200.  155200.   78740.  153067.4 143200.  249843.2 156640.  258640.\n",
      " 229386.4  85880.  152000.  217100.  104678.6  83540.  178600.  247080.\n",
      " 192700.  272786.4 215875.  117700.  173610.  182740.  135040.  129200.\n",
      " 180088.  262865.6 256980.  201200.  149000.  177380.  104678.6 138880.\n",
      " 122200.  131900.  205940.  131780.  200056.  107200.  122700.  190680.\n",
      " 128700.  194470.  255740.  229386.4 152000.  131900.  173380.  220780.\n",
      "  82760.  173380.  150486.8 226403.   91451.2 416331.4 198598.  306701.8\n",
      " 118480.  229386.4 416331.4 416557.4 225533.  141700.  144992.8 116000.\n",
      " 358433.6 272786.4 263218.4  94400.  219777.  293559.8 166700.  174740.\n",
      " 141390.  175100.  168680.  320964.8 220480.  166800.  268100.  118500.\n",
      " 124500.  261445.6 133250.  152140.  246280.  252080.  135040.  220780.\n",
      " 483778.8 196197.8  85880.  112950. ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2201189723.286301"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 引数\n",
    "\n",
    "# L１のインスタンス\n",
    "neigh_stacking_a0 = KNeighborsRegressor()\n",
    "neigh_stacking_a1 = KNeighborsRegressor()\n",
    "neigh_stacking_a2 = KNeighborsRegressor()\n",
    "neigh_stacking_a3 = KNeighborsRegressor()\n",
    "instance_a = [neigh_stacking_a0, neigh_stacking_a1, neigh_stacking_a2, neigh_stacking_a3]\n",
    "\n",
    "\n",
    "neigh_stacking_b0 = KNeighborsRegressor()\n",
    "neigh_stacking_b1 = KNeighborsRegressor()\n",
    "neigh_stacking_b2 = KNeighborsRegressor()\n",
    "neigh_stacking_b3 = KNeighborsRegressor()\n",
    "instance_b = [neigh_stacking_b0, neigh_stacking_b1, neigh_stacking_b2, neigh_stacking_b3]\n",
    "\n",
    "\n",
    "neigh_stacking_c0 = KNeighborsRegressor()\n",
    "neigh_stacking_c1 = KNeighborsRegressor()\n",
    "neigh_stacking_c2 = KNeighborsRegressor()\n",
    "neigh_stacking_c3 = KNeighborsRegressor()\n",
    "instance_c = [neigh_stacking_c0, neigh_stacking_c1, neigh_stacking_c2, neigh_stacking_c3]\n",
    "\n",
    "model_instance = [instance_a, instance_b, instance_c]\n",
    "\n",
    "# L2のインスタンス\n",
    "l2__instance = KNeighborsRegressor()\n",
    "\n",
    "\n",
    "\n",
    "# インスタンス化\n",
    "stacking_1 = ScratchStacking()\n",
    "stacking_1.fit(X_train_scaled, y_train, model_instance, l2__instance)\n",
    "\n",
    "# 推定\n",
    "y_pred_b = stacking_1.predict(X_test_scaled)\n",
    "stacking_1.MSE(y_test, y_pred_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "単独で実施した時が2138338000のため、やや精度が下がった。  \n",
    "単独のモデルを使うより、いろいろなモデルを組み合わせる方が良いと思われる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### パターン２\n",
    "ステージ０をSVM、最近傍法、決定木で構成。最終ステージは線形回帰で構成。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[207859.16150009 142898.01735589 123820.15145362 194757.53938354\n",
      " 120767.50754581  84551.38196558 207305.83909884 124219.36888441\n",
      " 443864.3615429  155258.03141519 204980.77232381 170142.21331652\n",
      " 238830.57669727 123009.86199102 126736.75256127 147135.21054727\n",
      " 224716.31885018 139826.90128446 153071.57518187 160798.17658257\n",
      " 156840.83944005 144226.49705424 114486.77524109 198257.79972328\n",
      " 183377.35770557 125517.90072559 235400.02904751 112045.15688217\n",
      " 305630.59835506 129155.1605065  183825.35746603 209127.86110221\n",
      " 128467.94926608 259178.75297014 347278.01050069 203349.48018841\n",
      " 213293.9130798  119277.55222869 311658.21251957 308972.36092774\n",
      " 219540.6793343  154324.44959388 207236.72116203 281059.24283766\n",
      " 366596.6611251  154902.54819515 110589.28548879 126900.8782707\n",
      " 181885.58889151 119158.09550088 393258.65163679 139346.51213015\n",
      " 154969.02686515  89541.1471766  196189.96435609 117274.34988881\n",
      " 130003.49074388 251246.25892811 144430.69402358 102775.4405392\n",
      " 137790.57796308 138799.34087265 147077.55894358 153336.12691383\n",
      " 204730.35697288 147653.99110527 121751.52711315 307634.76518295\n",
      " 107805.74693406 196117.07336134 193132.88816439 106189.54716333\n",
      " 121168.9470408  183995.84247056 121280.59901991 279810.69951286\n",
      " 134604.07510076 102405.41862495 327005.81239989 156872.59647812\n",
      " 130553.95884503 133800.8867671  130132.4029988  139826.90128446\n",
      " 294282.40669992 198553.07521403 103182.62088884 201172.44406893\n",
      " 191753.86186052 141198.13521688 226387.40000982 195263.41323775\n",
      " 208700.43450197 252043.06324855 176559.07803193 159143.88392132\n",
      " 189718.03996221 142000.67914426 117850.25927639 148115.96251421\n",
      " 248212.22443458 266137.70006773 150148.49780256 169469.61692186\n",
      "  86639.77812259 323616.64780644 185860.77603127 100325.07514607\n",
      " 206957.19260832 132642.92201525  83910.5654838  141726.60492054\n",
      " 188824.49152597 107643.01357643 179203.90244432 198053.09079562\n",
      " 328787.13206321 139175.83652535 223192.96255085 310079.58874279\n",
      " 155364.34081307 198329.59158456 135840.33040246 213053.57920564\n",
      " 221705.13584077 235942.17291789 344287.63548073 204665.3242563\n",
      " 178134.6901625  191324.93136389 190988.3969153  179548.59216065\n",
      " 245233.91605836 161180.32188945 117850.25927639 226388.01072164\n",
      " 139450.94149225 185227.86737227 108843.2045303  199155.44909397\n",
      " 130645.58092175 154257.17240333 233223.38629054 148836.62288487\n",
      " 124306.98083705 203486.14713465 207494.97640602 137522.73326419\n",
      " 256090.18285372 197119.60718387 161170.68922231 306637.17547283\n",
      " 245474.86562325 141160.95373773 157746.60832612 266270.41193023\n",
      " 108011.09461594 154208.54118532 150148.39851864 194571.69741012\n",
      " 117364.33823799 146274.07017736 233304.70350354 127422.26436661\n",
      " 233707.41203983 148483.4020771  156522.06583101 305583.93832285\n",
      " 200565.37474593 241132.2044535  158019.11450239 174163.57108336\n",
      " 204379.06582484 166772.10493696 126435.50819812 120035.84134952\n",
      " 139206.038488   252398.82838522 112496.63702361 149043.24216522\n",
      " 231076.60685595 191071.78965402 107917.13951767 304655.99752066\n",
      "  94017.63232818 175542.41588625 134125.52952278 177848.15030888\n",
      " 193933.80776113 144226.49705424 139826.90128446 150204.77252333\n",
      " 237654.82208762 138304.71050587 108033.9025155  140811.23818759\n",
      " 112045.15688217 139801.76013151 150883.26272294 152087.42080187\n",
      " 151371.64779879 174168.73818474  84437.77030452 147059.38321634\n",
      " 151538.98836853 249400.7465843  139368.99230683 252381.59660769\n",
      " 239084.84755855  88415.92320383 153572.14352968 209723.06749205\n",
      " 105997.9645964   84823.37345988 193864.06464824 219019.74204246\n",
      " 168806.82066196 277127.08636947 270103.98296613 112020.24419855\n",
      " 167601.99676683 152811.69779787 139703.37090921 117559.92657144\n",
      " 204374.35517177 267534.45812771 244833.99504451 190089.52846362\n",
      " 150075.69408772 164263.340828   106189.40347777 110961.79225306\n",
      " 117364.33823799 160235.88921319 210676.49603758 128114.90341074\n",
      " 188158.57972261 112522.15243184 126134.89433758 152519.77209729\n",
      " 128579.93953534 218395.9328072  264534.35343729 239084.99773469\n",
      " 153646.05110641 160753.52893392 177528.35952207 206298.16039521\n",
      " 115805.38001219 177219.99081384 157806.5361671  273560.16548504\n",
      "  90809.48406153 481620.96339129 201597.05087246 281059.24283766\n",
      " 104817.78306943 238758.40274006 455391.11170456 449754.98449295\n",
      " 224914.05838539 145712.88502335 178603.65932852 108234.30554852\n",
      " 343156.4564386  278889.22797923 249860.62585305  73693.17491745\n",
      " 206834.18520511 292525.04947723 148094.81486761 192121.21110321\n",
      " 139337.7152581  172503.03019369 166813.85959108 335558.65750161\n",
      " 214805.74428824 154869.55016553 261593.00580815 111238.79908092\n",
      " 125503.0944394  268150.49063526 136987.19619728 137412.60351232\n",
      " 206528.69411236 205147.92257362 140784.81156305 206294.60931232\n",
      " 381516.9442034  202601.74204531  88961.47644629  98403.09811895]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2068602443.268628"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 引数\n",
    "\n",
    "# L１のインスタンス\n",
    "svm_stacking_0 = SVR()\n",
    "svm_stacking_1 = SVR()\n",
    "svm_stacking_2 = SVR()\n",
    "svm_stacking_3 = SVR()\n",
    "instance_a = [svm_stacking_0, svm_stacking_1, svm_stacking_2, svm_stacking_3]\n",
    "\n",
    "neigh_stacking_0 = KNeighborsRegressor(n_neighbors=5)\n",
    "neigh_stacking_1 = KNeighborsRegressor(n_neighbors=5)\n",
    "neigh_stacking_2 = KNeighborsRegressor(n_neighbors=5)\n",
    "neigh_stacking_3 = KNeighborsRegressor(n_neighbors=5)\n",
    "instance_b = [neigh_stacking_0, neigh_stacking_1, neigh_stacking_2, neigh_stacking_3]\n",
    "\n",
    "tree_stacking_0 = DecisionTreeRegressor()\n",
    "tree_stacking_1 = DecisionTreeRegressor()\n",
    "tree_stacking_2 = DecisionTreeRegressor()\n",
    "tree_stacking_3 = DecisionTreeRegressor()\n",
    "instance_c = [tree_stacking_0, tree_stacking_1, tree_stacking_2, tree_stacking_3]\n",
    "\n",
    "model_instance = [instance_a, instance_b, instance_c]\n",
    "\n",
    "# L2のインスタンス\n",
    "l2__instance = LinearRegression()\n",
    "\n",
    "\n",
    "\n",
    "# インスタンス化\n",
    "stacking_1 = ScratchStacking()\n",
    "stacking_1.fit(X_train_scaled, y_train, model_instance, l2__instance)\n",
    "\n",
    "# 推定\n",
    "y_pred_b = stacking_1.predict(X_test_scaled)\n",
    "stacking_1.MSE(y_test, y_pred_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "単に４つのモデルを組み合わせただけで精度が向上し、すべてのベースラインを上回った。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### パターン３  \n",
    "最終ステージは精度の高い最近傍法で構成。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[308837.2 161800.  114950.  251272.6 135768.8  94955.2 181400.  127200.\n",
      " 410354.8 166930.  189990.  181510.  263658.  124380.  119480.  139800.\n",
      " 261514.4 157640.  127490.  151640.  126060.  148860.  120140.  191617.\n",
      " 204600.  123960.  210648.6 111950.  270600.  127350.  163906.6 169600.\n",
      " 137590.  308910.6 292604.8 185700.  200700.  127850.  286452.2 326820.\n",
      " 259418.  158050.  197659.  204960.  470348.8 176800.  106160.  136800.\n",
      " 181160.  104340.  300689.4 147900.  160780.  107800.  213800.  124380.\n",
      " 124370.  190860.  131900.  113500.  133100.  128430.  158040.  149900.\n",
      " 202448.6 137280.  120901.6 301190.  106180.  222530.  208800.  131700.\n",
      " 112680.8 163780.  116156.6 263200.  132460.  112180.  309380.  146160.\n",
      " 141680.  127100.  101480.8 157640.  325843.8 172178.   93880.  174968.\n",
      " 191160.  132580.  176400.  187879.  210316.  223208.  180279.  165000.\n",
      " 172413.  139760.  126500.  143400.  210660.  266450.6 142600.  155000.\n",
      "  72842.2 376367.4 192520.  106000.  210720.  111280.8  66322.2 137380.\n",
      " 169600.  115380.  177220.  176120.  361967.4 125300.  216400.  255580.\n",
      " 165530.  198446.  133670.  207380.  205160.  205712.2 353626.  189259.\n",
      " 187379.  162500.  185280.  187379.  255580.  167400.  126500.  177600.\n",
      " 126100.  187000.  113700.  197544.  132000.  165530.  178280.  152160.\n",
      " 146140.  205900.  202200.  134240.  241243.4 198446.  137280.  255998.6\n",
      " 256794.  123300.  145800.  325843.8 120901.6 161620.  160700.  189226.2\n",
      " 126500.  143440.  231800.  113380.  267930.2 124500.  147580.  339527.4\n",
      " 189990.  213134.  152420.  184560.  184859.  147867.4 117656.6 135768.8\n",
      " 131600.  237700.  106580.  146160.  252312.2 188160.  108210.  244700.\n",
      " 110000.  189800.  118630.  176278.  186160.  148860.  157640.  131600.\n",
      " 219960.  159500.  106180.  121540.  111950.  131600.  189628.  153180.\n",
      " 146160.  168000.  100155.2 155640.  154400.  296872.2 146200.  252760.\n",
      " 250774.   90580.  168300.  176400.  112480.  100200.  168200.  255380.\n",
      " 151800.  325843.8 308120.4 111950.  176478.  124480.  147900.  124380.\n",
      " 177580.  273080.  254458.  207728.6 146300.  156180.  106600.  123056.6\n",
      " 126500.  149480.  189380.  154780.  224020.  115180.  131200.  145100.\n",
      " 132430.  189515.6 233100.  250774.  146460.  140100.  171140.  182000.\n",
      " 118630.  191900.  132980.  255580.   86800.  492738.8 201516.  204960.\n",
      " 106180.  267930.2 495407.4 542586.6 231540.  147200.  190326.2 105756.\n",
      " 269780.  190860.  332560.   66322.2 172217.  301190.  137040.  174358.\n",
      " 142400.  186480.  133084.4 292964.6 248818.  169600.  240259.8 101378.6\n",
      " 117470.  255380.  148200.  157660.  189259.  248818.  123700.  202348.6\n",
      " 444102.2 207380.   91600.  109210. ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2898919417.7445207"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 引数\n",
    "\n",
    "# L１のインスタンス\n",
    "svm_stacking_0 = SVR()\n",
    "svm_stacking_1 = SVR()\n",
    "svm_stacking_2 = SVR()\n",
    "svm_stacking_3 = SVR()\n",
    "instance_a = [svm_stacking_0, svm_stacking_1, svm_stacking_2, svm_stacking_3]\n",
    "\n",
    "tree_stacking_0 = DecisionTreeRegressor()\n",
    "tree_stacking_1 = DecisionTreeRegressor()\n",
    "tree_stacking_2 = DecisionTreeRegressor()\n",
    "tree_stacking_3 = DecisionTreeRegressor()\n",
    "instance_b = [tree_stacking_0, tree_stacking_1, tree_stacking_2, tree_stacking_3]\n",
    "\n",
    "linear_stacking_0 = LinearRegression()\n",
    "linear_stacking_1 = LinearRegression()\n",
    "linear_stacking_2 = LinearRegression()\n",
    "linear_stacking_3 = LinearRegression()\n",
    "instance_c = [linear_stacking_0, linear_stacking_1, linear_stacking_2, linear_stacking_3]\n",
    "\n",
    "model_instance = [instance_a, instance_b, instance_c]\n",
    "\n",
    "# L2のインスタンス\n",
    "l2__instance = KNeighborsRegressor(n_neighbors=5)\n",
    "\n",
    "\n",
    "\n",
    "# インスタンス化\n",
    "stacking_1 = ScratchStacking()\n",
    "stacking_1.fit(X_train_scaled, y_train, model_instance, l2__instance)\n",
    "\n",
    "# 推定\n",
    "y_pred_b = stacking_1.predict(X_test_scaled)\n",
    "stacking_1.MSE(y_test, y_pred_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "逆に精度が下がったことを確認。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### パターン４  \n",
    "最終ステージを決定木に変更して実施。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[350000. 146150. 119500. 210000. 132500. 109500. 185000. 119500. 184750.\n",
      " 180000. 254000. 187000. 211000. 157500. 124000. 170000. 215000. 150750.\n",
      " 165500. 115000. 143000. 140000. 139000. 177000. 183000. 124000. 179500.\n",
      "  68400. 255000. 144000. 159895. 277000. 144000. 394617. 465000. 254000.\n",
      " 277000. 129000. 239686. 260000. 277000. 178000. 254000. 318061. 466500.\n",
      " 143900. 110000. 127500. 173500.  62383. 380000. 143000. 180000.  80000.\n",
      " 185000. 127000. 114504. 235000. 142000. 163500. 129500. 128000. 150000.\n",
      " 150000. 325000.  97000. 153900. 297000.  68400. 210000. 185000. 128000.\n",
      " 153900. 173500. 153900. 293077. 108000. 163500. 340000. 143000. 143750.\n",
      " 108000. 124000. 150750. 302000. 157000. 116900. 177000. 160000. 143000.\n",
      " 277000. 157000. 185000. 199900. 185000. 152000. 185000. 157000. 127000.\n",
      " 113000. 235000. 254900. 152000. 149500.  73000. 275500. 164700. 115000.\n",
      " 185000. 114504. 100000. 143000. 173000. 128000. 173500. 160000. 340000.\n",
      " 126500. 186500. 233230. 180000. 185000.  89500. 277000. 179500. 179500.\n",
      " 465000. 254000. 185000. 160000. 157000. 185000. 219500. 147400. 127000.\n",
      " 277000. 153000. 159895. 128000. 185000. 130500. 180000. 235000. 150000.\n",
      " 112000. 177000. 179500. 139000. 235000. 185000. 115000. 297000. 199900.\n",
      " 175500. 143000. 359100. 128000. 150000. 149500. 145000. 127000. 124000.\n",
      " 277000. 127500. 277000. 140000. 127000. 268000. 254000. 277000. 180500.\n",
      " 142600. 254000. 200100. 124000.  89500. 159950. 248000. 128000. 113000.\n",
      " 229000. 183000.  68400. 297000.  88000. 185000. 107400. 185000. 185000.\n",
      " 140000. 150750. 144000. 179500. 164000.  68400. 163000.  68400. 143000.\n",
      " 143900. 127000. 165500. 162000. 119000. 170000. 127000. 328000. 153000.\n",
      " 250000. 235000.  73000. 134432. 277000. 128000. 130000. 193000. 280000.\n",
      " 149500. 302000. 277000. 116900. 214500. 127000. 165000. 127000. 186500.\n",
      " 254900. 219500. 185000. 148000. 167000. 128000. 128000. 127000. 115000.\n",
      " 186500. 149900. 173500. 105500. 129000. 127000. 144000. 277000. 235000.\n",
      " 235000. 159000. 115000. 185000. 325000. 105000. 173500. 159000. 222000.\n",
      " 108000. 625000. 254000. 318061. 120000. 277000. 625000. 184750. 277000.\n",
      " 170000. 185000.  68400. 465000. 318000. 359100.  39300. 254000. 297000.\n",
      " 165000. 160000. 153000. 174000. 118500. 402861. 277000. 180000. 239000.\n",
      " 128000. 127000. 254900. 148000. 164000. 254000. 325000. 150750. 325000.\n",
      " 380000. 325000. 102776. 115000.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3875421174.8150687"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 引数\n",
    "\n",
    "# L１のインスタンス\n",
    "svm_stacking_0 = SVR()\n",
    "svm_stacking_1 = SVR()\n",
    "svm_stacking_2 = SVR()\n",
    "svm_stacking_3 = SVR()\n",
    "instance_a = [svm_stacking_0, svm_stacking_1, svm_stacking_2, svm_stacking_3]\n",
    "\n",
    "neigh_stacking_0 = KNeighborsRegressor(n_neighbors=5)\n",
    "neigh_stacking_1 = KNeighborsRegressor(n_neighbors=5)\n",
    "neigh_stacking_2 = KNeighborsRegressor(n_neighbors=5)\n",
    "neigh_stacking_3 = KNeighborsRegressor(n_neighbors=5)\n",
    "instance_b = [neigh_stacking_0, neigh_stacking_1, neigh_stacking_2, neigh_stacking_3]\n",
    "\n",
    "linear_stacking_0 = LinearRegression()\n",
    "linear_stacking_1 = LinearRegression()\n",
    "linear_stacking_2 = LinearRegression()\n",
    "linear_stacking_3 = LinearRegression()\n",
    "instance_c = [linear_stacking_0, linear_stacking_1, linear_stacking_2, linear_stacking_3]\n",
    "\n",
    "model_instance = [instance_a, instance_b, instance_c]\n",
    "\n",
    "# L2のインスタンス\n",
    "l2__instance = DecisionTreeRegressor()\n",
    "\n",
    "\n",
    "\n",
    "# インスタンス化\n",
    "stacking_1 = ScratchStacking()\n",
    "stacking_1.fit(X_train_scaled, y_train, model_instance, l2__instance)\n",
    "\n",
    "# 推定\n",
    "y_pred_b = stacking_1.predict(X_test_scaled)\n",
    "stacking_1.MSE(y_test, y_pred_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "さらに精度が下がったことを確認。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### パターン５  \n",
    "最終ステージをSVMに変更して実施。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[163373.45700179 163025.46140013 162952.13394242 163289.15229499\n",
      " 162959.1673551  162989.19784696 163335.41859479 162950.94298557\n",
      " 163208.0391862  163091.33815593 163299.52327678 163206.36772102\n",
      " 163409.5385202  162942.59156801 162940.79794071 163032.20541667\n",
      " 163403.98589579 163002.54352777 162994.48194581 163052.02616348\n",
      " 163036.29383798 163018.00397263 162948.19039117 163341.32858044\n",
      " 163309.74427842 162939.27448837 163371.05062854 162952.09458379\n",
      " 163352.54140121 162952.54147634 163208.95361314 163360.6141231\n",
      " 162949.5394835  163392.72956337 163322.22455342 163273.39239809\n",
      " 163326.71181859 162946.87784952 163363.58978508 163327.60995369\n",
      " 163385.30758111 163085.75698815 163280.42869413 163391.56153273\n",
      " 163237.04412458 163155.76465104 162940.78912179 162956.94130143\n",
      " 163263.80204678 162947.37622336 163244.45921027 162996.61974203\n",
      " 163103.43927719 162974.61712767 163310.49183063 162941.83195583\n",
      " 162972.24626586 163393.62873467 162981.98700318 162951.62351994\n",
      " 162973.74326952 162959.87696234 163010.53708222 163010.74463263\n",
      " 163349.94658807 163062.74603162 162937.58831086 163349.82014687\n",
      " 162944.2091498  163359.40428671 163298.30308534 162955.01061171\n",
      " 162937.94318547 163298.36702752 162944.21304693 163387.65783842\n",
      " 162968.86169683 162954.37034923 163314.77723157 163034.90040845\n",
      " 162972.52640663 162952.03413077 162941.20484389 163002.54352777\n",
      " 163325.58035879 163297.31164926 162944.08937599 163314.11400789\n",
      " 163275.73056629 162976.54041143 163371.08577739 163241.27518224\n",
      " 163349.8119659  163407.78368556 163223.55180379 163153.45723869\n",
      " 163315.5277028  163020.14468552 162939.987339   163036.54080782\n",
      " 163409.74037582 163389.05655811 163028.66965768 163182.26917664\n",
      " 163030.86204494 163313.33839625 163217.32424536 162948.46456438\n",
      " 163304.81615871 162944.14193648 163062.55051969 162965.05621403\n",
      " 163320.58503402 162939.82309291 163243.58002577 163241.00480717\n",
      " 163302.14126282 162963.58594139 163395.97526122 163369.03354406\n",
      " 163077.53664082 163336.3186127  162985.93881754 163341.82937597\n",
      " 163353.07469284 163395.49559147 163308.82948432 163275.0158795\n",
      " 163222.36612843 163320.96882135 163258.40724817 163224.64539089\n",
      " 163408.30521053 163145.00550446 162939.987339   163370.89892155\n",
      " 163016.36493935 163236.77248311 162938.73184793 163300.96520032\n",
      " 162949.82761227 163077.83116042 163386.25924708 162995.00218237\n",
      " 163006.70207622 163302.98999597 163335.93470494 162969.97229473\n",
      " 163407.88538762 163342.72114274 163090.0491796  163283.92708848\n",
      " 163410.40757439 163032.16727    163058.55869508 163352.3297804\n",
      " 162938.54235815 163020.01089813 163113.29064074 163309.05068844\n",
      " 162940.34727941 163017.46655848 163389.99236982 162949.61886511\n",
      " 163399.73916806 162974.25283654 163086.02779607 163345.21689468\n",
      " 163297.86215907 163397.89205689 163072.52736354 163179.66921681\n",
      " 163275.4764937  163050.1218006  162946.735576   162959.97062381\n",
      " 162982.08572078 163383.58945598 162939.43749181 163023.40757914\n",
      " 163403.34628571 163303.32668443 162963.43249234 163304.38990307\n",
      " 162958.54347401 163237.4180871  162960.44891683 163246.46198624\n",
      " 163260.85401356 163018.00397263 163002.54352777 163070.18341224\n",
      " 163393.98150628 162996.29842657 162945.30030916 163007.73137448\n",
      " 162952.09458379 162980.73999889 163128.32494275 163103.39955875\n",
      " 163022.56743267 163149.5767799  162984.57236506 163011.27898424\n",
      " 163044.53225818 163388.91687531 163092.722141   163401.85783522\n",
      " 163406.3382941  163010.44139129 163095.00389126 163341.5705488\n",
      " 162940.86178055 162997.93670193 163329.83048698 163400.65202005\n",
      " 163137.32819155 163342.08501411 163355.72694903 162950.21005194\n",
      " 163224.582925   163081.25040382 162992.10007821 162942.15651996\n",
      " 163319.59404274 163392.17535944 163411.16787639 163325.06240538\n",
      " 163084.13364086 163156.8807266  162946.51430569 162943.23304959\n",
      " 162940.34727941 163075.76737406 163363.10052262 162969.43753014\n",
      " 163339.32811564 162940.75722356 162953.88139559 163066.28424182\n",
      " 162959.72259915 163374.50897343 163405.70765065 163406.30467119\n",
      " 163100.9036238  163022.57532378 163172.25124678 163339.78119623\n",
      " 162953.81935688 163234.23570611 163088.73883867 163400.88084769\n",
      " 162995.52572689 163214.14181171 163333.57393986 163391.56153273\n",
      " 162948.00037909 163401.98688353 163214.65180621 163207.52646962\n",
      " 163399.1713375  163042.53206994 163268.36814552 162968.00762372\n",
      " 163283.74457248 163394.21113399 163350.13466903 163070.68458844\n",
      " 163346.01625911 163328.40135736 162985.39900785 163256.71986395\n",
      " 163033.7707698  163204.19013826 163111.37116098 163334.45532966\n",
      " 163387.89054654 163103.30268619 163392.83901162 162953.62915995\n",
      " 162948.07303463 163403.7006743  162998.95268714 163038.36845929\n",
      " 163276.43046496 163379.13404153 162989.35824553 163358.47678802\n",
      " 163230.12326121 163329.85753562 163011.57389852 162968.29956528]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7220395064.6483755"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 引数\n",
    "\n",
    "# L１のインスタンス\n",
    "tree_stacking_0 = DecisionTreeRegressor()\n",
    "tree_stacking_1 = DecisionTreeRegressor()\n",
    "tree_stacking_2 = DecisionTreeRegressor()\n",
    "tree_stacking_3 = DecisionTreeRegressor()\n",
    "instance_a = [tree_stacking_0, tree_stacking_1, tree_stacking_2, tree_stacking_3]\n",
    "\n",
    "neigh_stacking_0 = KNeighborsRegressor(n_neighbors=5)\n",
    "neigh_stacking_1 = KNeighborsRegressor(n_neighbors=5)\n",
    "neigh_stacking_2 = KNeighborsRegressor(n_neighbors=5)\n",
    "neigh_stacking_3 = KNeighborsRegressor(n_neighbors=5)\n",
    "instance_b = [neigh_stacking_0, neigh_stacking_1, neigh_stacking_2, neigh_stacking_3]\n",
    "\n",
    "linear_stacking_0 = LinearRegression()\n",
    "linear_stacking_1 = LinearRegression()\n",
    "linear_stacking_2 = LinearRegression()\n",
    "linear_stacking_3 = LinearRegression()\n",
    "instance_c = [linear_stacking_0, linear_stacking_1, linear_stacking_2, linear_stacking_3]\n",
    "\n",
    "model_instance = [instance_a, instance_b, instance_c]\n",
    "\n",
    "# L2のインスタンス\n",
    "l2__instance = SVR()\n",
    "\n",
    "\n",
    "\n",
    "# インスタンス化\n",
    "stacking_1 = ScratchStacking()\n",
    "stacking_1.fit(X_train_scaled, y_train, model_instance, l2__instance)\n",
    "\n",
    "# 推定\n",
    "y_pred_b = stacking_1.predict(X_test_scaled)\n",
    "stacking_1.MSE(y_test, y_pred_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最さらに精度が下がったことを確認。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 考察  \n",
    "ステージ０をSVM、最近傍法、決定木、最終ステージを線形回帰で構成したときにベースラインを上回ることができた。  \n",
    "個別で精度が高いからと言って単独のモデルでスタッキングを構成しても精度は上がらず、 \n",
    "むしろ下がる結果になった。  \n",
    "また、いろいろなモデルを組み合わせるとしても、ステージ０と最終ステージの組み合わせによって  \n",
    "かなり差が出ることが分かった。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2次元の畳み込みニューラルネットワークスクラッチ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### データセットの用意\n",
    "引き続きMNISTデータセットを使用します。2次元畳み込み層へは、28×28の状態で入力します。\n",
    "\n",
    "\n",
    "今回は白黒画像ですからチャンネルは1つしかありませんが、チャンネル方向の軸は用意しておく必要があります。\n",
    "\n",
    "\n",
    "`(n_samples, n_channels, height, width)`の`NCHW`または`(n_samples, height, width, n_channels)`の`NHWC`どちらかの形にしてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n",
      "(60000,)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape) # (48000, 784)\n",
    "print(X_test.shape) # (12000, 784)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 1, 28, 28)\n",
      "(10000, 1, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# 軸を追加\n",
    "X_train=X_train[:, np.newaxis, :]\n",
    "X_test=X_test[:, np.newaxis, :]\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000,)\n",
      "(60000, 10)\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n",
    "y_test_one_hot = enc.transform(y_test[:, np.newaxis])\n",
    "print(y_train.shape) # (60000,)\n",
    "print(y_train_one_hot.shape) # (60000, 10)\n",
    "print(y_train_one_hot.dtype) # float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 1, 10)\n"
     ]
    }
   ],
   "source": [
    "# 軸を追加\n",
    "y_train_one_hot=y_train_one_hot[:, np.newaxis, :]\n",
    "#y_test_one_hot=y_test_one_hot[:, np.newaxis, :]\n",
    "print(y_train_one_hot.shape)\n",
    "#print(y_test_one_hot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48000, 1, 28, 28)\n",
      "(12000, 1, 28, 28)\n",
      "(48000, 1, 10)\n",
      "(12000, 1, 10)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train_one_hot, test_size=0.2)\n",
    "print(X_train.shape) # (48000, 784)\n",
    "print(X_val.shape) # (12000, 784)\n",
    "print(y_train.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12000,)\n",
      "[4 2 7 ... 4 1 2]\n"
     ]
    }
   ],
   "source": [
    "# テスト用にデコード\n",
    "y_test_decode = np.argmax(y_val, axis=2).reshape(-1,)\n",
    "print(y_test_decode.shape)\n",
    "print(y_test_decode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題1】2次元畳み込み層の作成  \n",
    ">1次元畳み込み層のクラスConv1dを発展させ、2次元畳み込み層のクラスConv2dを作成してください。\n",
    ">\n",
    ">フォワードプロパゲーションの数式は以下のようになります。\n",
    ">\n",
    ">$\n",
    "a_{i,j,m} = \\sum_{k=0}^{K-1}\\sum_{s=0}^{F_{h}-1}\\sum_{t=0}^{F_{w}-1}x_{(i+s),(j+t),k}w_{s,t,k,m}+b_{m}\n",
    "$\n",
    ">\n",
    ">ai,j,m : 出力される配列のi行j列、mチャンネルの値\n",
    ">\n",
    ">i : 配列の行方向のインデックス\n",
    ">\n",
    ">j : 配列の列方向のインデックス\n",
    ">\n",
    ">m : 出力チャンネルのインデックス\n",
    ">\n",
    ">K : 入力チャンネル数\n",
    ">\n",
    ">Fh,Fw : 高さ方向（h）と幅方向（w）のフィルタのサイズ\n",
    ">\n",
    ">x(i+s),(j+t),k : 入力の配列の(i+s)行(j+t)列、kチャンネルの値\n",
    ">\n",
    ">ws,t,k,m : 重みの配列のs行t列目。kチャンネルの入力に対して、mチャンネルへ出力する重み\n",
    ">\n",
    ">bm : mチャンネルへの出力のバイアス項\n",
    ">\n",
    ">全てスカラーです。\n",
    ">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">次に更新式です。1次元畳み込み層や全結合層と同じ形です。\n",
    ">\n",
    ">$\n",
    "w_{s,t,k,m}^{\\prime} = w_{s,t,k,m} - \\alpha \\frac{\\partial L}{\\partial w_{s,t,k,m}} \\\\\n",
    "b_{m}^{\\prime} = b_{m} - \\alpha \\frac{\\partial L}{\\partial b_{m}}\n",
    "$\n",
    ">\n",
    ">α : 学習率\n",
    ">\n",
    ">$\\frac{\\partial L}{\\partial w_{s,t,k,m}}$: $w_{s,t,k,m}$に関する損失 L の勾配\n",
    ">\n",
    ">$\\frac{\\partial L}{\\partial b_{m}}$: bm に関する損失 L の勾配\n",
    ">\n",
    ">勾配$\\frac{\\partial L}{\\partial w_{s,t,k,m}}$や$\\frac{\\partial L}{\\partial b_{m}}$を求めるためのバックプロパゲーションの数式が以下である。\n",
    ">\n",
    ">$\n",
    "\\frac{\\partial L}{\\partial w_{s,t,k,m}} = \\sum_{i=0}^{N_{out,h}-1}\\sum_{j=0}^{N_{out,w}-1} \\frac{\\partial L}{\\partial a_{i,j,m}}x_{(i+s)(j+t),k}\\\\\n",
    "\\frac{\\partial L}{\\partial b_{m}} = \\sum_{i=0}^{N_{out,h}-1}\\sum_{j=0}^{N_{out,w}-1}\\frac{\\partial L}{\\partial a_{i,j,m}}\n",
    "$\n",
    ">\n",
    ">$\\frac{\\partial L}{\\partial a_i}$ : 勾配の配列のi行j列、mチャンネルの値\n",
    ">\n",
    ">$N_{out,h},N_{out,w}$: 高さ方向（h）と幅方向（w）の出力のサイズ\n",
    ">\n",
    ">前の層に流す誤差の数式は以下です。\n",
    ">\n",
    ">$\n",
    "\\frac{\\partial L}{\\partial x_{i,j,k}} = \\sum_{m=0}^{M-1}\\sum_{s=0}^{F_{h}-1}\\sum_{t=0}^{F_{w}-1} \\frac{\\partial L}{\\partial a_{(i-s),(j-t),m}}w_{s,t,k,m}\n",
    "$\n",
    ">\n",
    ">$\\frac{\\partial L}{\\partial x_{i,j,k}}$: 前の層に流す誤差の配列のi列j行、kチャンネルの値\n",
    ">\n",
    ">M  : 出力チャンネル数\n",
    ">\n",
    ">ただし、  $i-s<0$または$i-s>N_{out,h}-1$または$j-t<0$または$j-t>N_{out,w}-1$のとき$\\frac{\\partial L}{\\partial a_{(i-s),(j-t),m}} =0$です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2d():\n",
    "    \"\"\"\n",
    "    ノード数n_nodes1からn_nodes2への全結合層\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_nodes1 : int\n",
    "      前の層のノード数\n",
    "    n_nodes2 : int\n",
    "      後の層のノード数\n",
    "    initializer : 初期化方法のインスタンス\n",
    "    optimizer : 最適化手法のインスタンス\n",
    "    \"\"\"\n",
    "    def __init__(self, n_filter, n_channel, Fs, Ft, initializer, optimizer):\n",
    "        self.optimizer = optimizer\n",
    "        # 初期化\n",
    "        # initializerのメソッドを使い、self.Wとself.Bを初期化する\n",
    "        self.n_filter = n_filter\n",
    "        self.n_channel = n_channel\n",
    "        self.Fs = Fs\n",
    "        self.Ft = Ft\n",
    "        \n",
    "        self.W = initializer.W(self.n_filter, self.n_channel, self.Fs, self.Ft)\n",
    "        self.B = initializer.B(self.n_filter)\n",
    "        \n",
    "    \n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        フォワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            入力\n",
    "        Returns\n",
    "        ----------\n",
    "        A : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            出力\n",
    "        \"\"\"\n",
    "        self.X = X\n",
    "        \n",
    "        self.n_input=self.X.shape[1]#.shape[1]\n",
    "        \n",
    "        self.n_input_h=self.X.shape[2]#.shape[1]\n",
    "        self.n_input_w=self.X.shape[3]#.shape[1]\n",
    "        \n",
    "        #F=3\n",
    "        stride=1\n",
    "        padding=0\n",
    "        #self.n_output1 = self.X_i - self.Fs\n",
    "        #self.n_output2 = self.X_j - self.Ft\n",
    "        self.n_output_h, self.n_output_w = self.output_size(self.n_input_h, self.n_input_w, self.Fs, self.Ft, P=padding, S=stride)\n",
    "        \n",
    "        A = np.empty((self.n_filter, self.n_channel, self.n_output_h, self.n_output_w))\n",
    "        for f in range(self.n_filter):#出力チャンネル\n",
    "            for c in range(self.n_channel):#入力チャンネル\n",
    "                for i in range(self.n_input_h - self.Fs):#self.n_output　　タテ\n",
    "                    for j in range(self.n_input_w - self.Ft):#self.n_output　ヨコ\n",
    "                        A[f, c, i, j] += np.sum(X[f, c, i:i+self.Fs:, j:j+self.Ft]*self.W[f, c])+self.B[f]\n",
    "   \n",
    "        self.A = A\n",
    "        \n",
    "        return self.A\n",
    "    \n",
    "    \n",
    "    def backward(self, dA, Z):\n",
    "        \"\"\"\n",
    "        バックワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        dA : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            後ろから流れてきた勾配\n",
    "        Returns\n",
    "        ----------\n",
    "        dZ : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            前に流す勾配\n",
    "        \"\"\"\n",
    "        # 実際の処理においてはラベルは不要\n",
    "        \n",
    "        # 更新\n",
    "        self, dZ = self.optimizer.update(self, dA, self.X)\n",
    "        \n",
    "        return dZ\n",
    "    \n",
    "    def output_size(self, n_input_h, n_input_w, Fs, Ft, P=0, S=1):\n",
    "        \"\"\"\n",
    "        出力数数える\n",
    "        \"\"\"\n",
    "        n_output_h = int((n_input_h + 2*P - Fs)/S + 1)\n",
    "        n_output_w = int((n_input_w + 2*P - Ft)/S + 1)\n",
    "\n",
    "        return (n_output_h, n_output_w)\n",
    "                 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 初期化方法のクラス化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleInitializer():\n",
    "    \"\"\"\n",
    "    ガウス分布によるシンプルな初期化\n",
    "    Parameters\n",
    "    ----------\n",
    "    sigma : float\n",
    "      ガウス分布の標準偏差\n",
    "    \"\"\"\n",
    "    def __init__(self, sigma):\n",
    "        self.sigma = sigma\n",
    "        \n",
    "    def W(self, n_filter, n_channel, Fs, Ft):\n",
    "        \"\"\"\n",
    "        重みの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_filter : int\n",
    "          フィルタのサイズ\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        W :\n",
    "        \"\"\"\n",
    "        W = self.sigma * np.random.randn(n_filter, n_channel, Fs, Ft)\n",
    "        \n",
    "        return W\n",
    "    \n",
    "    \n",
    "    def B(self, n_filter):\n",
    "        \"\"\"\n",
    "        バイアスの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes2 : int\n",
    "          後の層のノード数\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        B :\n",
    "        \"\"\"\n",
    "        B = self.sigma * np.random.randn(n_filter, )\n",
    "        \n",
    "        return B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 更新式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RenewalFormula():\n",
    "    \"\"\"\n",
    "    確率的勾配降下法\n",
    "    Parameters\n",
    "    ----------\n",
    "    lr : 学習率\n",
    "    \"\"\"\n",
    "    def __init__(self, lr):\n",
    "        self.lr = lr\n",
    "        \n",
    "    def update(self, layer, dA, X):#dA, Z\n",
    "        \"\"\"\n",
    "        ある層の重みやバイアスの更新\n",
    "        Parameters\n",
    "        ----------\n",
    "        layer : 更新前の層のインスタンス\n",
    "        \"\"\"\n",
    "        #print(f\"dA.shape：　{dA.shape}\")\n",
    "            \n",
    "        dA_num = layer.n_output_h*layer.n_output_w\n",
    "        dW_temp = np.zeros((layer.n_filter, dA_num, layer.n_channel, layer.Fs, layer.Ft))\n",
    "        #print(f\"layer.n_output_h：　{layer.n_output_h}\")\n",
    "        #print(f\"layer.n_output_w：　{layer.n_output_w}\")\n",
    "        \n",
    "        for f in range(layer.n_filter):\n",
    "            for c in range(layer.n_channel):\n",
    "                a = 0\n",
    "                for i in range(layer.n_output_h):\n",
    "                    for j in range(layer.n_output_w):\n",
    "                        dW_temp[f, a, c] += layer.W[f, c]*dA[f, c, i, j]\n",
    "                        a += 1\n",
    "\n",
    "        #print(f\"dW_temp.shape：　{dW_temp.shape}\")\n",
    "        \n",
    "        \n",
    "        dW = np.sum(dW_temp, axis=1)\n",
    "        #print(f\"dW.shape：　{dW.shape}\")\n",
    "        \n",
    "        # (48000, 1, 28, 28)\n",
    "        #print(f\"X.shape：　{X.shape}\")\n",
    "        dX=np.zeros(X.shape)\n",
    "        \n",
    "        for f in range(layer.n_filter):\n",
    "            for c in range(layer.n_channel):\n",
    "                a = 0\n",
    "                for i in range(layer.n_output_h):\n",
    "                    for j in range(layer.n_output_w):\n",
    "                        dX[f, c, i:i+layer.Fs, j:j+layer.Ft] += dW[f, c]\n",
    "                        a += 1\n",
    "        \n",
    "        #　バイアスの更新\n",
    "        dB = np.sum(dA, axis=(1,2, 3))#, axis=0 , axis=1\n",
    "        #print(f\"dB.shape：　{dB.shape}\")\n",
    "        \n",
    "        layer.W = layer.W - self.lr*(dW)\n",
    "        layer.B = layer.B - self.lr*(dB)\n",
    "        \n",
    "        return (layer, dX)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 活性化関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tanh():\n",
    "    \"\"\"\n",
    "    活性化関数（シグモイド関数）のクラス\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    \"\"\"\n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        準伝播用\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            訓練データ\n",
    "        \"\"\"\n",
    "        Z = np.tanh(X)\n",
    "        \n",
    "        return Z\n",
    "    \n",
    "\n",
    "    def backward(self, X, dZ):\n",
    "        \"\"\"\n",
    "        逆伝播用\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            訓練データ\n",
    "        \"\"\"\n",
    "        dA = dZ*(1 - np.tanh(X)**2)\n",
    "        \n",
    "        return dA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### インスタンス化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W.shape: (4, 1, 3, 3)\n",
      "B.shape: (4,)\n"
     ]
    }
   ],
   "source": [
    "initializer=SimpleInitializer(0.01)\n",
    "optimizer=RenewalFormula(1)\n",
    "n_filter=4#写真の枚数と同じ\n",
    "n_channel=1#白黒、RGB\n",
    "Fs=3\n",
    "Ft=3\n",
    "# インスタンス化\n",
    "CNN_conv2d = Conv2d(n_filter, n_channel, Fs, Ft, initializer, optimizer)\n",
    "\n",
    "print(\"W.shape: {}\".format(CNN_conv2d.W.shape))\n",
    "print(\"B.shape: {}\".format(CNN_conv2d.B.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 1, 26, 26)\n"
     ]
    }
   ],
   "source": [
    "# CNN　順伝播\n",
    "CNN_conv2d.forward(X_train[0:4])\n",
    "A=CNN_conv2d.A\n",
    "print(A.shape)\n",
    "#print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 1, 26, 26)\n"
     ]
    }
   ],
   "source": [
    "# 活性化関数　順伝播\n",
    "tanh = Tanh()\n",
    "Z = tanh.forward(A)\n",
    "print(Z.shape)\n",
    "#print(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 1, 26, 26)\n"
     ]
    }
   ],
   "source": [
    "# 活性化関数　逆伝播\n",
    "dA = tanh.backward(A, Z)#本当はdZ\n",
    "print(dA.shape)\n",
    "#print(dA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dX.shape：　(4, 1, 28, 28)\n",
      "dX：　[[[[ 0.10561713  0.12815135  0.13577607 ...  0.13577607  0.03015893\n",
      "     0.00762472]\n",
      "   [ 0.12175163  0.04597762  0.2092768  ...  0.2092768   0.08752517\n",
      "     0.16329918]\n",
      "   [ 0.09998831  0.08884563  0.28216584 ...  0.28216584  0.18217753\n",
      "     0.19332021]\n",
      "   ...\n",
      "   [ 0.09998831  0.08884563  0.28216584 ...  0.28216584  0.18217753\n",
      "     0.19332021]\n",
      "   [-0.00562882 -0.03930572  0.14638977 ...  0.14638977  0.15201859\n",
      "     0.18569549]\n",
      "   [-0.02176332  0.04286801  0.07288904 ...  0.07288904  0.09465236\n",
      "     0.03002103]]]\n",
      "\n",
      "\n",
      " [[[ 0.03930765  0.26171075  0.36598669 ...  0.36598669  0.32667905\n",
      "     0.10427595]\n",
      "   [ 0.17888583  0.28396661 -0.13615064 ... -0.13615064 -0.31503647\n",
      "    -0.42011725]\n",
      "   [ 0.11208131  0.5523926   0.22380343 ...  0.22380343  0.11172212\n",
      "    -0.32858917]\n",
      "   ...\n",
      "   [ 0.11208131  0.5523926   0.22380343 ...  0.22380343  0.11172212\n",
      "    -0.32858917]\n",
      "   [ 0.07277366  0.29068186 -0.14218326 ... -0.14218326 -0.21495692\n",
      "    -0.43286512]\n",
      "   [-0.06680453  0.26842599  0.35995407 ...  0.35995407  0.42675859\n",
      "     0.09152807]]]\n",
      "\n",
      "\n",
      " [[[ 0.02797947 -0.06110089 -0.09941921 ... -0.09941921 -0.12739868\n",
      "    -0.03831832]\n",
      "   [ 0.02969046 -0.08749191 -0.06871385 ... -0.06871385 -0.09840431\n",
      "     0.01877806]\n",
      "   [ 0.19094361  0.10070951  0.26734671 ...  0.26734671  0.0764031\n",
      "     0.16663721]\n",
      "   ...\n",
      "   [ 0.19094361  0.10070951  0.26734671 ...  0.26734671  0.0764031\n",
      "     0.16663721]\n",
      "   [ 0.16296414  0.16181039  0.36676592 ...  0.36676592  0.20380179\n",
      "     0.20495553]\n",
      "   [ 0.16125315  0.18820142  0.33606057 ...  0.33606057  0.17480742\n",
      "     0.14785915]]]\n",
      "\n",
      "\n",
      " [[[ 0.02487467  0.00512383  0.03972574 ...  0.03972574  0.01485107\n",
      "     0.03460191]\n",
      "   [ 0.04374792 -0.05320871  0.00189192 ...  0.00189192 -0.041856\n",
      "     0.05510063]\n",
      "   [ 0.12050228 -0.0782873  -0.02603891 ... -0.02603891 -0.14654119\n",
      "     0.0522484 ]\n",
      "   ...\n",
      "   [ 0.12050228 -0.0782873  -0.02603891 ... -0.02603891 -0.14654119\n",
      "     0.0522484 ]\n",
      "   [ 0.09562762 -0.08341113 -0.06576465 ... -0.06576465 -0.16139226\n",
      "     0.01764648]\n",
      "   [ 0.07675436 -0.02507859 -0.02793082 ... -0.02793082 -0.10468519\n",
      "    -0.00285223]]]]\n"
     ]
    }
   ],
   "source": [
    "# CNN　逆伝播\n",
    "dX = CNN_conv2d.backward(dA, X_train[0:4])\n",
    "print(f\"dX.shape：　{dX.shape}\")\n",
    "print(f\"dX：　{dX}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題2】2次元畳み込み後の出力サイズ  \n",
    ">畳み込みを行うと特徴マップのサイズが変化します。どのように変化するかは以下の数式から求められます。この計算を行う関数を作成してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "クラス内にoutput_sizeメソッドを作成。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "高さのアウトプット数：　26\n",
      "幅のアウトプット数：　26\n"
     ]
    }
   ],
   "source": [
    "n_input_h = 28\n",
    "n_input_w = 28\n",
    "Fs = 3\n",
    "Ft = 3\n",
    "P=0\n",
    "S=1\n",
    "\n",
    "n_output_h, n_output_w = CNN_conv2d.output_size(n_input_h, \n",
    "                                                                                                n_input_w, \n",
    "                                                                                                Fs, \n",
    "                                                                                                Ft, \n",
    "                                                                                                P=P,\n",
    "                                                                                                S=S\n",
    "                                                                                               )\n",
    "print(f\"高さのアウトプット数：　{n_output_h}\")\n",
    "print(f\"幅のアウトプット数：　{n_output_w}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題3】最大プーリング層の作成  \n",
    ">最大プーリング層のクラスMaxPool2Dを作成してください。  \n",
    ">プーリング層は数式で表さない方が分かりやすい部分もありますが、数式で表すとフォワードプロパゲーションは以下のようになります。\n",
    ">\n",
    ">$\n",
    "a_{i,j,k} = \\max_{(p,q)\\in P_{i,j}}x_{p,q,k}\n",
    "$\n",
    ">\n",
    ">Pi,j : i行j列への出力する場合の入力配列のインデックスの集合。 \n",
    ">\n",
    ">Sh×Sw の範囲内の行（p）と列（q）\n",
    ">\n",
    ">Sh,Sw : 高さ方向（h）と幅方向（w）のストライドのサイズ\n",
    ">\n",
    ">(p,q)∈Pi,j : Pi,j に含まれる行（p）と列（q）のインデックス\n",
    ">\n",
    ">ai,j,m : 出力される配列のi行j列、kチャンネルの値\n",
    ">\n",
    ">xp,q,k : 入力の配列のp行q列、kチャンネルの値\n",
    ">\n",
    ">ある範囲の中でチャンネル方向の軸は残したまま最大値を計算することになります。\n",
    ">バックプロパゲーションのためには、フォワードプロパゲーションのときの最大値のインデックス \n",
    "(p,q) を保持しておく必要があります。フォワード時に最大値を持っていた箇所にそのままの誤差を流し、そこ以外には0を入れるためです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxPool2D():\n",
    "    \"\"\"\n",
    "    ノード数n_nodes1からn_nodes2への全結合層\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_nodes1 : int\n",
    "      前の層のノード数\n",
    "    n_nodes2 : int\n",
    "      後の層のノード数\n",
    "    initializer : 初期化方法のインスタンス\n",
    "    optimizer : 最適化手法のインスタンス\n",
    "    \"\"\"\n",
    "    def __init__(self, n_filter, n_channel, Sh, Sw):\n",
    "        #self.optimizer = optimizer\n",
    "        # 初期化\n",
    "        # initializerのメソッドを使い、self.Wとself.Bを初期化する\n",
    "        self.n_filter = n_filter\n",
    "        self.n_channel = n_channel\n",
    "        self.Sh = Sh\n",
    "        self.Sw = Sw\n",
    "        \n",
    "    \n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        フォワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            入力\n",
    "        Returns\n",
    "        ----------\n",
    "        A : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            出力\n",
    "        \"\"\"\n",
    "        self.X = X\n",
    "        #print(X.shape)\n",
    "        self.n_input=self.X.shape[1]#.shape[1]\n",
    "        \n",
    "        self.n_input_h=self.X.shape[2]#.shape[1]\n",
    "        self.n_input_w=self.X.shape[3]#.shape[1]\n",
    "        \n",
    "        self.n_output_h=int(self.n_input_h/self.Sh)\n",
    "        self.n_output_w=int(self.n_input_w/self.Sw)\n",
    "        \n",
    "        A = np.empty((self.n_filter, self.n_channel, self.n_output_h, self.n_output_w))\n",
    "        A_index = []\n",
    "        \n",
    "        for f in range(self.n_filter):#出力チャンネル\n",
    "            for c in range(self.n_channel):#入力チャンネル\n",
    "                for i in range(self.n_output_h):#self.n_output　　タテ 【割り切れる数】\n",
    "                    for j in range(self.n_output_w):#self.n_output　ヨコ 【割り切れる数】\n",
    "                        A[f, c, i, j] = np.max(X[f, c, i*self.Sh:i*self.Sh+self.Sh:, j*self.Sw:j*self.Sw+self.Sw])\n",
    "\n",
    "                    \n",
    "        self.A = A\n",
    "        #print(f\"self.A.shape：　{self.A.shape}\")\n",
    "        \n",
    "        return self.A\n",
    "    \n",
    "    \n",
    "    def backward(self, A):\n",
    "        \"\"\"\n",
    "        バックワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        dA : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            後ろから流れてきた勾配\n",
    "        Returns\n",
    "        ----------\n",
    "        dZ : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            前に流す勾配\n",
    "        \"\"\"\n",
    "        # 実際の処理においてはラベルは不要\n",
    "        \n",
    "        # 更新\n",
    "        X_max = np.zeros(self.X.shape)\n",
    "        self.A\n",
    "        a = 0\n",
    "        for f in range(self.n_filter):#出力チャンネル\n",
    "            for c in range(self.n_channel):#入力チャンネル\n",
    "                for i in range(self.n_output_h):#self.n_output　　タテ\n",
    "                    for j in range(self.n_output_w):#self.n_output　ヨコ \n",
    "                        for h in range(self.Sw):#self.Sw　　タテ\n",
    "                            for w in range(self.Sw):#self.Sw　ヨコ\n",
    "                                # マックスプーリングの値と一致するXはそのままXの値を入力\n",
    "                                if self.A[f, c, i, j]==self.X[f, c, i*self.Sh+h, j*self.Sw+w]:\n",
    "                                    X_max[f, c, i, j] = self.X[f, c, i*self.Sh+h, j*self.Sw+w]\n",
    "\n",
    "        self.X_max = X_max\n",
    "        \n",
    "        return self.X_max\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_filter=4#写真の枚数と同じ\n",
    "n_channel=1#白黒、RGB\n",
    "Sh=4#【割り切れる数】\n",
    "Sw=4#【割り切れる数】\n",
    "\n",
    "# インスタンス化\n",
    "max_pool_2d = MaxPool2D(n_filter, n_channel, Sh, Sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A_max.shape：　(4, 1, 7, 7)\n",
      "A_max：　[[[[ 0.28216584  0.28216584  0.28216584  0.28216584  0.28216584\n",
      "     0.28216584  0.28216584]\n",
      "   [ 0.28216584  0.28216584  0.28216584  0.28216584  0.28216584\n",
      "     0.28216584  0.28216584]\n",
      "   [ 0.28216584  0.28216584  0.28216584  0.28216584  0.28216584\n",
      "     0.28216584  0.28216584]\n",
      "   [ 0.28216584  0.28216584  0.28216584  0.28216584  0.28216584\n",
      "     0.28216584  0.28216584]\n",
      "   [ 0.28216584  0.28216584  0.28216584  0.28216584  0.28216584\n",
      "     0.28216584  0.28216584]\n",
      "   [ 0.28216584  0.28216584  0.28216584  0.28216584  0.28216584\n",
      "     0.28216584  0.28216584]\n",
      "   [ 0.28216584  0.28216584  0.28216584  0.28216584  0.28216584\n",
      "     0.28216584  0.28216584]]]\n",
      "\n",
      "\n",
      " [[[ 0.5523926   0.36598669  0.36598669  0.36598669  0.36598669\n",
      "     0.36598669  0.36598669]\n",
      "   [ 0.5523926   0.22380343  0.22380343  0.22380343  0.22380343\n",
      "     0.22380343  0.22380343]\n",
      "   [ 0.5523926   0.22380343  0.22380343  0.22380343  0.22380343\n",
      "     0.22380343  0.22380343]\n",
      "   [ 0.5523926   0.22380343  0.22380343  0.22380343  0.22380343\n",
      "     0.22380343  0.22380343]\n",
      "   [ 0.5523926   0.22380343  0.22380343  0.22380343  0.22380343\n",
      "     0.22380343  0.22380343]\n",
      "   [ 0.5523926   0.22380343  0.22380343  0.22380343  0.22380343\n",
      "     0.22380343  0.22380343]\n",
      "   [ 0.5523926   0.35995407  0.35995407  0.35995407  0.35995407\n",
      "     0.35995407  0.42675859]]]\n",
      "\n",
      "\n",
      " [[[ 0.26734671  0.26734671  0.26734671  0.26734671  0.26734671\n",
      "     0.26734671  0.26734671]\n",
      "   [ 0.26734671  0.26734671  0.26734671  0.26734671  0.26734671\n",
      "     0.26734671  0.26734671]\n",
      "   [ 0.26734671  0.26734671  0.26734671  0.26734671  0.26734671\n",
      "     0.26734671  0.26734671]\n",
      "   [ 0.26734671  0.26734671  0.26734671  0.26734671  0.26734671\n",
      "     0.26734671  0.26734671]\n",
      "   [ 0.26734671  0.26734671  0.26734671  0.26734671  0.26734671\n",
      "     0.26734671  0.26734671]\n",
      "   [ 0.26734671  0.26734671  0.26734671  0.26734671  0.26734671\n",
      "     0.26734671  0.26734671]\n",
      "   [ 0.36676592  0.36676592  0.36676592  0.36676592  0.36676592\n",
      "     0.36676592  0.36676592]]]\n",
      "\n",
      "\n",
      " [[[ 0.12050228  0.03972574  0.03972574  0.03972574  0.03972574\n",
      "     0.03972574  0.05510063]\n",
      "   [ 0.12050228 -0.02603891 -0.02603891 -0.02603891 -0.02603891\n",
      "    -0.02603891  0.0522484 ]\n",
      "   [ 0.12050228 -0.02603891 -0.02603891 -0.02603891 -0.02603891\n",
      "    -0.02603891  0.0522484 ]\n",
      "   [ 0.12050228 -0.02603891 -0.02603891 -0.02603891 -0.02603891\n",
      "    -0.02603891  0.0522484 ]\n",
      "   [ 0.12050228 -0.02603891 -0.02603891 -0.02603891 -0.02603891\n",
      "    -0.02603891  0.0522484 ]\n",
      "   [ 0.12050228 -0.02603891 -0.02603891 -0.02603891 -0.02603891\n",
      "    -0.02603891  0.0522484 ]\n",
      "   [ 0.12050228 -0.02603891 -0.02603891 -0.02603891 -0.02603891\n",
      "    -0.02603891  0.0522484 ]]]]\n"
     ]
    }
   ],
   "source": [
    "A_max = max_pool_2d.forward(dX)\n",
    "print(f\"A_max.shape：　{A_max.shape}\")\n",
    "print(f\"A_max：　{A_max}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_max.shape：　(4, 1, 28, 28)\n",
      "X_max：　[[[[ 0.28216584  0.28216584  0.28216584 ...  0.          0.\n",
      "     0.        ]\n",
      "   [ 0.28216584  0.28216584  0.28216584 ...  0.          0.\n",
      "     0.        ]\n",
      "   [ 0.28216584  0.28216584  0.28216584 ...  0.          0.\n",
      "     0.        ]\n",
      "   ...\n",
      "   [ 0.          0.          0.         ...  0.          0.\n",
      "     0.        ]\n",
      "   [ 0.          0.          0.         ...  0.          0.\n",
      "     0.        ]\n",
      "   [ 0.          0.          0.         ...  0.          0.\n",
      "     0.        ]]]\n",
      "\n",
      "\n",
      " [[[ 0.5523926   0.36598669  0.36598669 ...  0.          0.\n",
      "     0.        ]\n",
      "   [ 0.5523926   0.22380343  0.22380343 ...  0.          0.\n",
      "     0.        ]\n",
      "   [ 0.5523926   0.22380343  0.22380343 ...  0.          0.\n",
      "     0.        ]\n",
      "   ...\n",
      "   [ 0.          0.          0.         ...  0.          0.\n",
      "     0.        ]\n",
      "   [ 0.          0.          0.         ...  0.          0.\n",
      "     0.        ]\n",
      "   [ 0.          0.          0.         ...  0.          0.\n",
      "     0.        ]]]\n",
      "\n",
      "\n",
      " [[[ 0.26734671  0.26734671  0.26734671 ...  0.          0.\n",
      "     0.        ]\n",
      "   [ 0.26734671  0.26734671  0.26734671 ...  0.          0.\n",
      "     0.        ]\n",
      "   [ 0.26734671  0.26734671  0.26734671 ...  0.          0.\n",
      "     0.        ]\n",
      "   ...\n",
      "   [ 0.          0.          0.         ...  0.          0.\n",
      "     0.        ]\n",
      "   [ 0.          0.          0.         ...  0.          0.\n",
      "     0.        ]\n",
      "   [ 0.          0.          0.         ...  0.          0.\n",
      "     0.        ]]]\n",
      "\n",
      "\n",
      " [[[ 0.12050228  0.03972574  0.03972574 ...  0.          0.\n",
      "     0.        ]\n",
      "   [ 0.12050228 -0.02603891 -0.02603891 ...  0.          0.\n",
      "     0.        ]\n",
      "   [ 0.12050228 -0.02603891 -0.02603891 ...  0.          0.\n",
      "     0.        ]\n",
      "   ...\n",
      "   [ 0.          0.          0.         ...  0.          0.\n",
      "     0.        ]\n",
      "   [ 0.          0.          0.         ...  0.          0.\n",
      "     0.        ]\n",
      "   [ 0.          0.          0.         ...  0.          0.\n",
      "     0.        ]]]]\n"
     ]
    }
   ],
   "source": [
    "X_max = max_pool_2d.backward(A_max)\n",
    "print(f\"X_max.shape：　{X_max.shape}\")\n",
    "print(f\"X_max：　{X_max}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題5】平滑化  \n",
    ">平滑化するためのFlattenクラスを作成してください。\n",
    ">\n",
    ">フォワードのときはチャンネル、高さ、幅の3次元を1次元にreshapeします。その値は記録しておき、バックワードのときに再びreshapeによって形を戻します。\n",
    ">\n",
    ">この平滑化のクラスを挟むことで出力前の全結合層に適した配列を作ることができます。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten():\n",
    "    \"\"\"\n",
    "    Flatten平滑化\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_nodes1 : int\n",
    "      前の層のノード数\n",
    "    n_nodes2 : int\n",
    "      後の層のノード数\n",
    "    initializer : 初期化方法のインスタンス\n",
    "    optimizer : 最適化手法のインスタンス\n",
    "    \"\"\"\n",
    "    def forward(self, X):\n",
    "        # チャンネル、高さ、幅の3次元を1次元にreshape\n",
    "        self.X = X\n",
    "        X_flat = X.reshape(X.shape[0],-1,1)\n",
    "        \n",
    "        return X_flat \n",
    "        \n",
    "    def backward(self, X):\n",
    "        # バックワードのときに再びreshapeによって形を戻します\n",
    "        X = X.reshape(self.X.shape)\n",
    "        \n",
    "        return X \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A_max.shape：　(4, 784, 1)\n"
     ]
    }
   ],
   "source": [
    "flat = Flatten()\n",
    "X_flat = flat.forward(X_max)\n",
    "print(f\"A_max.shape：　{X_flat.shape}\")\n",
    "#print(f\"X_flat：　{X_flat}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A_max.shape：　(4, 1, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "X_restore = flat.backward(X_flat)\n",
    "print(f\"A_max.shape：　{X_restore.shape}\")\n",
    "#print(f\"_restore：　{_restore}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 検証"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題6】学習と推定  \n",
    ">作成したConv2dを使用してMNISTを学習・推定し、Accuracyを計算してください。\n",
    ">\n",
    ">精度は低くともまずは動くことを目指してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FC():\n",
    "    \"\"\"\n",
    "    ノード数n_nodes1からn_nodes2への全結合層\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_nodes1 : int\n",
    "      前の層のノード数\n",
    "    n_nodes2 : int\n",
    "      後の層のノード数\n",
    "    initializer : 初期化方法のインスタンス\n",
    "    optimizer : 最適化手法のインスタンス\n",
    "    \"\"\"\n",
    "    def __init__(self, n_nodes1, n_nodes2, initializer, optimizer):\n",
    "        self.optimizer = optimizer\n",
    "        # 初期化\n",
    "        # initializerのメソッドを使い、self.Wとself.Bを初期化する\n",
    "        self.W = initializer.W(n_nodes1, n_nodes2)\n",
    "        self.B = initializer.B(n_nodes2)\n",
    "    \n",
    "    \n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        フォワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            入力\n",
    "        Returns\n",
    "        ----------\n",
    "        A : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            出力\n",
    "        \"\"\"\n",
    "        self.X = X\n",
    "        \n",
    "        A=[]\n",
    "        for f in range(self.X.shape[0]):\n",
    "            A_temp = self.X[f,:].T@self.W[f,:]+self.B.reshape(-1,1).T\n",
    "            A.append(A_temp)\n",
    "        \n",
    "        return np.array(A)\n",
    "    \n",
    "    \n",
    "    def backward(self, dA, Z):\n",
    "        \"\"\"\n",
    "        バックワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        dA : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            後ろから流れてきた勾配\n",
    "        Returns\n",
    "        ----------\n",
    "        dZ : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            前に流す勾配\n",
    "        \"\"\"\n",
    "        # 更新\n",
    "        self, dZ = self.optimizer.update(self, dA, Z)\n",
    "        \n",
    "        return dZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleInitializerFC:\n",
    "    \"\"\"\n",
    "    ガウス分布によるシンプルな初期化\n",
    "    Parameters\n",
    "    ----------\n",
    "    sigma : float\n",
    "      ガウス分布の標準偏差\n",
    "    \"\"\"\n",
    "    def __init__(self, sigma):\n",
    "        self.sigma = sigma\n",
    "        \n",
    "    def W(self, n_nodes1, n_nodes2):\n",
    "        \"\"\"\n",
    "        重みの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes1 : int\n",
    "          前の層のノード数\n",
    "        n_nodes2 : int\n",
    "          後の層のノード数\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        W :\n",
    "        \"\"\"\n",
    "        W = self.sigma * np.random.randn(4, n_nodes1, n_nodes2)\n",
    "        \n",
    "        return W\n",
    "    \n",
    "    \n",
    "    def B(self, n_nodes2):\n",
    "        \"\"\"\n",
    "        バイアスの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes2 : int\n",
    "          後の層のノード数\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        B :\n",
    "        \"\"\"\n",
    "        B = self.sigma * np.random.randn(n_nodes2,)\n",
    "        \n",
    "        return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGD:\n",
    "    \"\"\"\n",
    "    確率的勾配降下法\n",
    "    Parameters\n",
    "    ----------\n",
    "    lr : 学習率\n",
    "    \"\"\"\n",
    "    def __init__(self, lr):\n",
    "        self.lr = lr\n",
    "        \n",
    "    def update(self, layer, dA, Z):#Z3, Y, \n",
    "        \"\"\"\n",
    "        ある層の重みやバイアスの更新\n",
    "        Parameters\n",
    "        ----------\n",
    "        layer : 更新前の層のインスタンス\n",
    "        \"\"\"\n",
    "        dB = np.sum(dA, axis=0)#バッチサイズ分の合計\n",
    "        \n",
    "        dW=[]\n",
    "        for f in range(dA.shape[0]):\n",
    "            dW.append(Z[f,:]*dA[f,:])\n",
    "        dW = np.array(dW)\n",
    "        \n",
    "        \n",
    "        dZ =[]\n",
    "        for f in range(layer.W.shape[0]):\n",
    "            dZ.append(layer.W[f,:]@dA[f,:].T)\n",
    "        dZ=np.array(dZ)\n",
    "        \n",
    "        #【問題3】\n",
    "        layer.W = layer.W - self.lr*(dW)\n",
    "        layer.B = layer.B - self.lr*(dB)\n",
    "        \n",
    "        \n",
    "        return (layer, np.array(dZ))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softmax():\n",
    "    \"\"\"\n",
    "    活性化関数（シグモイド関数）のクラス\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    \"\"\"\n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        準伝播用\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            訓練データ\n",
    "        \"\"\"\n",
    "        Z = np.exp(X)/(np.sum(np.exp(X)))#, axis=()\n",
    "        \n",
    "        return Z\n",
    "    \n",
    "\n",
    "    def backward(self, X, y):\n",
    "        \"\"\"\n",
    "        逆伝播用\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            訓練データ\n",
    "        \"\"\"\n",
    "        dA =X - y\n",
    "        \n",
    "        # 目的関数（損失関数）　交差エントロピー誤差\n",
    "        nb = y.shape[0]#バッチサイズ\n",
    "        L = -(1/nb)*(np.sum(y*np.log(X)))\n",
    "        \n",
    "        return (dA, L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### インスタンス化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FC インスタンス化\n",
    "FC_Q6 = FC(36,10, SimpleInitializerFC(0.01), SGD(0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W.shape: (4, 1, 3, 3)\n",
      "B.shape: (4,)\n"
     ]
    }
   ],
   "source": [
    "# Conv2d インスタンス化\n",
    "\n",
    "initializer=SimpleInitializer(0.01)\n",
    "optimizer=RenewalFormula(1)\n",
    "n_filter=4#写真の枚数と同じ\n",
    "n_channel=1#白黒、RGB\n",
    "Fs=3\n",
    "Ft=3\n",
    "# インスタンス化\n",
    "CNN_conv2d_Q6 = Conv2d(n_filter, n_channel, Fs, Ft, initializer, optimizer)\n",
    "\n",
    "print(\"W.shape: {}\".format(CNN_conv2d_Q6.W.shape))\n",
    "print(\"B.shape: {}\".format(CNN_conv2d_Q6.B.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MaxPool2D　インスタンス化\n",
    "\n",
    "n_filter=4#写真の枚数と同じ\n",
    "n_channel=1#白黒、RGB\n",
    "Sh=4#【割り切れる数】\n",
    "Sw=4#【割り切れる数】\n",
    "\n",
    "# インスタンス化\n",
    "max_pool_2d_Q6 = MaxPool2D(n_filter, n_channel, Sh, Sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# インスタンス化\n",
    "tanh_Q6 = Tanh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# インスタンス化\n",
    "softmax_Q6 = Softmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# インスタンス化\n",
    "flat_Q6 = Flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 順伝播"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN　順伝播：　(4, 1, 26, 26)\n",
      "活性化関数　順伝播：　(4, 1, 26, 26)\n",
      "Max Poolinb　順伝播：　(4, 1, 6, 6)\n",
      "Flatten　順伝播：　(4, 36, 1)\n",
      "全結合層　順伝播：　(4, 1, 10)\n",
      "softmax関数　順伝播：　(4, 1, 10)\n"
     ]
    }
   ],
   "source": [
    "# CNN　順伝播\n",
    "A1_q6=CNN_conv2d_Q6.forward(X_train[0:4])#0:4\n",
    "print(f\"CNN　順伝播：　{A1_q6.shape}\")\n",
    "# 活性化関数　順伝播\n",
    "Z1_q6 = tanh_Q6.forward(A1_q6)\n",
    "print(f\"活性化関数　順伝播：　{Z1_q6.shape}\")\n",
    "# Max Poolinb　順伝播\n",
    "X_max_q6 = max_pool_2d_Q6.forward(Z1_q6)\n",
    "print(f\"Max Poolinb　順伝播：　{X_max_q6.shape}\")\n",
    "# Flatten　順伝播\n",
    "X_flat_q6 = flat.forward(X_max_q6)\n",
    "print(f\"Flatten　順伝播：　{X_flat_q6.shape}\")\n",
    "# 全結合層　順伝播\n",
    "A3_q6 = FC_Q6.forward(X_flat_q6)\n",
    "print(f\"全結合層　順伝播：　{A3_q6.shape}\")\n",
    "# 活性化関数　順伝播\n",
    "Z3_q6 = softmax_Q6.forward(A3_q6)\n",
    "print(f\"softmax関数　順伝播：　{Z3_q6.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 逆伝播"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "活性化関数　逆伝播：　(4, 1, 10)\n",
      "全結合層　逆伝播：　(4, 36, 1)\n",
      "Flatten　逆伝播：　(4, 1, 6, 6)\n",
      "Max Poolinb　逆伝播：　(4, 1, 26, 26)\n",
      "活性化関数　逆伝播：　(4, 1, 26, 26)\n",
      "CNN　逆伝播：　(4, 1, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# 活性化関数　逆伝播\n",
    "dA3_q6, _ = softmax_Q6.backward(Z3_q6, y_train[0:4])#  A3_q6\n",
    "print(f\"活性化関数　逆伝播：　{dA3_q6.shape}\")\n",
    "# 全結合層　逆伝播\n",
    "dZ2_q6 = FC_Q6.backward(dA3_q6, X_flat_q6)#dA2, Z1\n",
    "print(f\"全結合層　逆伝播：　{dZ2_q6.shape}\")\n",
    "# Flatten　逆伝播\n",
    "X_restore_q6 = flat.backward(dZ2_q6)\n",
    "print(f\"Flatten　逆伝播：　{X_restore_q6.shape}\")\n",
    "# Max Poolinb　逆伝播\n",
    "X_max_q6 = max_pool_2d_Q6.backward(X_restore_q6)\n",
    "print(f\"Max Poolinb　逆伝播：　{X_max_q6.shape}\")\n",
    "# 活性化関数　逆伝播\n",
    "dA_q6 = tanh_Q6.backward(A1_q6, X_max_q6)\n",
    "print(f\"活性化関数　逆伝播：　{dA_q6.shape}\")\n",
    "# CNN　逆伝播\n",
    "dX_q6 = CNN_conv2d_Q6.backward(dA_q6, X_train[0:4])\n",
    "print(f\"CNN　逆伝播：　{dX_q6.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 推定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN　順伝播：　(4, 1, 26, 26)\n",
      "活性化関数　順伝播：　(4, 1, 26, 26)\n",
      "Max Poolinb　順伝播：　(4, 1, 6, 6)\n",
      "Flatten　順伝播：　(4, 36, 1)\n",
      "全結合層　順伝播：　(4, 1, 10)\n",
      "活性化関数　順伝播：　(4, 1, 10)\n"
     ]
    }
   ],
   "source": [
    "# CNN　順伝播\n",
    "A1_pred=CNN_conv2d_Q6.forward(X_val[0:4])#0:4\n",
    "print(f\"CNN　順伝播：　{A1_pred.shape}\")\n",
    "# 活性化関数　順伝播\n",
    "Z1_pred = tanh_Q6.forward(A1_pred)\n",
    "print(f\"活性化関数　順伝播：　{Z1_pred.shape}\")\n",
    "# Max Poolinb　順伝播\n",
    "X_max_pred = max_pool_2d_Q6.forward(Z1_pred)\n",
    "print(f\"Max Poolinb　順伝播：　{X_max_pred.shape}\")\n",
    "# Flatten　順伝播\n",
    "X_flat_pred = flat.forward(X_max_pred)\n",
    "print(f\"Flatten　順伝播：　{X_flat_pred.shape}\")\n",
    "# 全結合層　順伝播\n",
    "A3_pred = FC_Q6.forward(X_flat_pred)\n",
    "print(f\"全結合層　順伝播：　{A3_pred.shape}\")\n",
    "# 活性化関数　順伝播\n",
    "Z3_pred = tanh_Q6.forward(A3_pred)\n",
    "print(f\"活性化関数　順伝播：　{Z3_pred.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-2.99912715e-02,  2.69500576e-02, -2.05726125e-02,\n",
       "         -1.09925164e-02, -5.64986711e-02,  2.03159718e-02,\n",
       "          5.20998575e-02,  4.22744812e-02, -2.61648367e-02,\n",
       "          3.56347876e-03]],\n",
       "\n",
       "       [[ 2.81036449e-02, -7.52138418e-02,  1.25786869e-03,\n",
       "          3.51966666e-02, -7.51072628e-05,  1.27545091e-01,\n",
       "          1.42579775e-01, -2.62974670e-02,  2.10693059e-02,\n",
       "         -3.92392273e-02]],\n",
       "\n",
       "       [[-2.18206881e-01, -8.49287857e-02,  7.30643980e-02,\n",
       "          3.28359765e-02, -8.82152978e-03,  4.23666560e-02,\n",
       "          7.37382212e-02, -2.70944919e-02, -5.53621853e-02,\n",
       "         -2.30988279e-03]],\n",
       "\n",
       "       [[ 2.84208752e-02, -3.18922837e-02,  5.63836654e-02,\n",
       "          1.58207437e-02,  1.07852756e-02,  6.83678510e-03,\n",
       "          9.80909611e-02,  3.14591211e-03,  4.67210804e-03,\n",
       "          1.11917649e-02]]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z3_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "推定結果： [6 6 6 6]\n",
      "正解： [4 2 7 5]\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.argmax(Z3_pred, axis=2).reshape(-1,)\n",
    "print(\"推定結果： {}\".format(y_pred))\n",
    "print(\"正解： {}\".format(y_test_decode[0:4]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test_decode[0:4], y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetMiniBatch:\n",
    "    \"\"\"\n",
    "    ミニバッチを取得するイテレータ\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "      訓練データ\n",
    "    y : 次の形のndarray, shape (n_samples, 1)\n",
    "      正解値\n",
    "    batch_size : int\n",
    "      バッチサイズ\n",
    "    seed : int\n",
    "      NumPyの乱数のシード\n",
    "    \"\"\"\n",
    "    def __init__(self, X, y, batch_size = 20, seed=0):\n",
    "        self.batch_size = batch_size\n",
    "        np.random.seed(seed)\n",
    "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
    "        self._X = X[shuffle_index]\n",
    "        self._y = y[shuffle_index]\n",
    "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n",
    "    def __len__(self):\n",
    "        return self._stop\n",
    "    def __getitem__(self,item):\n",
    "        p0 = item*self.batch_size\n",
    "        p1 = item*self.batch_size + self.batch_size\n",
    "        return self._X[p0:p1], self._y[p0:p1]        \n",
    "    def __iter__(self):\n",
    "        self._counter = 0\n",
    "        return self\n",
    "    def __next__(self):\n",
    "        if self._counter >= self._stop:\n",
    "            raise StopIteration()\n",
    "        p0 = self._counter*self.batch_size\n",
    "        p1 = self._counter*self.batch_size + self.batch_size\n",
    "        self._counter += 1\n",
    "        return self._X[p0:p1], self._y[p0:p1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss Curv用のリスト\n",
    "L_list = []\n",
    "epoch=8\n",
    "batch_size=4\n",
    "\n",
    "for i in range(epoch):\n",
    "    get_mini_batch = GetMiniBatch(X_train[0:64], y_train[0:64], batch_size)# ミニバッチ\n",
    "    for mini_X_train, mini_y_train in get_mini_batch:\n",
    "        \n",
    "        # CNN　順伝播\n",
    "        A1_q6=CNN_conv2d_Q6.forward(mini_X_train)#0:4\n",
    "        # 活性化関数　順伝播\n",
    "        Z1_q6 = tanh_Q6.forward(A1_q6)\n",
    "        # Max Poolinb　順伝播\n",
    "        X_max_q6 = max_pool_2d_Q6.forward(Z1_q6)\n",
    "        # Flatten　順伝播\n",
    "        X_flat_q6 = flat.forward(X_max_q6)\n",
    "        # 全結合層　順伝播\n",
    "        A3_q6 = FC_Q6.forward(X_flat_q6)\n",
    "        # 活性化関数　順伝播\n",
    "        Z3_q6 = softmax_Q6.forward(A3_q6)\n",
    "\n",
    "\n",
    "        # 活性化関数　逆伝播\n",
    "        dA3_q6, L = softmax_Q6.backward(Z3_q6, mini_y_train)#  A3_q6\n",
    "        # 全結合層　逆伝播\n",
    "        dZ2_q6 = FC_Q6.backward(dA3_q6, X_flat_q6)#dA2, Z1\n",
    "        # Flatten　逆伝播\n",
    "        X_restore_q6 = flat.backward(dZ2_q6)\n",
    "        # Max Poolinb　逆伝播\n",
    "        X_max_q6 = max_pool_2d_Q6.backward(X_restore_q6)\n",
    "        # 活性化関数　逆伝播\n",
    "        dA_q6 = tanh_Q6.backward(A1_q6, X_max_q6)\n",
    "        # CNN　逆伝播\n",
    "        dX_q6 = CNN_conv2d_Q6.backward(dA_q6, mini_X_train)\n",
    "        \n",
    "    \"\"\"\n",
    "    Loss Curvを描くための処理\n",
    "    \"\"\"\n",
    "    L_list.append(L)\n",
    "    #L_list = np.array(L_list) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X_val):\n",
    "    # CNN　順伝播\n",
    "    A1_pred=CNN_conv2d_Q6.forward(X_val)#0:4\n",
    "    # 活性化関数　順伝播\n",
    "    Z1_pred = tanh_Q6.forward(A1_pred)\n",
    "    # Max Poolinb　順伝播\n",
    "    X_max_pred = max_pool_2d_Q6.forward(Z1_pred)\n",
    "    # Flatten　順伝播\n",
    "    X_flat_pred = flat.forward(X_max_pred)\n",
    "    # 全結合層　順伝播\n",
    "    A3_pred = FC_Q6.forward(X_flat_pred)\n",
    "    # 活性化関数　順伝播\n",
    "    Z3_pred = tanh_Q6.forward(A3_pred)\n",
    "    \n",
    "    y_pred = np.argmax(Z3_pred, axis=2).reshape(-1,)\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "推定結果： [3 2 9 6]\n",
      "正解： [4 2 7 5]\n"
     ]
    }
   ],
   "source": [
    "y_pred = predict(X_val[0:4])\n",
    "print(\"推定結果： {}\".format(y_pred))\n",
    "print(\"正解： {}\".format(y_test_decode[0:4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test_decode[0:4], y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 損失関数グラフ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fbd503e32d0>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3deXxUhbn/8c+TBRKWsIY1gbAjIgQJmygoLhcVcUHBVqu4463V1lZv7/31ttXrba31qtdqxRVxF7BY9Fo3LCKVLSBYkB0SwiZhCXsghOf3xxxoGpMQQobJZL7v12teTGbOnHkmtfnOec45zzF3R0REYldcpAsQEZHIUhCIiMQ4BYGISIxTEIiIxDgFgYhIjFMQiIjEOAWB1Bpm9pCZbTOzLaf4fceb2X+eyveMFDMba2azIl2HVC8FgVQrM8sxswsi8L7pwE+BHu7eKozv850/hO4+zt3/K1zvWUEt55rZETPbW+o26FTXItEtIdIFiFST9sB2d98a6UJOsU3unhbpIiS6aYtAThkzu83MVpvZDjObZmZtgsfNzB43s61mtsvMvjaznsFzl5jZN2a2x8w2mtnPyljvBcAnQJvgG/HLwbflDaWWO7a1Yma/NrNJZvZKsO6lZpZVYtl0M/uTmeWb2XYze8rMTgPGA4OC9ykIln3ZzB463ucMnnMzG2dmq8xsp5k9bWZWnb/nEu81w8x+a2bzgt/rn82saYnnRwafuyBY9rSKPn+pdT8a1L/OzC4OR/1y6igI5JQws2HAb4HRQGsgF3grePoiYAjQFWgMjAG2B8+9CNzh7g2BnsBnpdft7p8CFxP6dtzA3cdWsqyRQQ2NgWnAU0Gt8cD7QY0ZQFvgLXdfBowDZgfv0/gEP+dRI4B+QO9guX+pZL1VcQNwM9AGOAw8GdTZFXgT+DGQCnwAvGdmdcr7/CXWOQBYATQHHgFeDFeYyamhIJBT5TrgJXdf6O4HgX8n9M06AygCGgLdAXP3Ze6+OXhdEdDDzFLcfae7L6zGmma5+wfuXgy8SugPM0B/Qn8473P3fe5e6O6V3UFa0ec86mF3L3D39cBfgcyT+Axtgm/0JW/1Szz/qrsvcfd9wH8Co4M/9GOA/3P3T9y9CHgUSAbO4vifP9fdnw9+bxMJBV7Lk/gMEmEKAjlV2hD6hgmAu+8l9K2/rbt/Rujb+NPAt2b2nJmlBIuOAi4Bcs3s82reEVry6KL9QJKZJQDphP7YHa7COsv9nBW8b4OyVlRqB3C7ct5vk7s3LnXbV+L5vBL3c4FEQt/kS9d5JFi2Lcf//FtKvG5/cLfMzyDRQUEgp8omQjt0AQi+tTYDNgK4+5Pu3hc4nVCL6L7g8fnufjnQAngXmFTJ99sH1CvxfvGEWiCVkQe0C0KhtOON663wc56IoP109Lb+RF8fSC9xvx2hLaxtZdRpwbIbqfjzSy2kIJBwSDSzpBK3BOAN4CYzyzSzusBvgLnunmNm/cxsgJklEvoDXggUB/3q68ysUdC+2A0UV7KGlYS+4V8arPcXQN1KvnYesBl42MzqB59hcPDct0CamdUp57Xlfs5Kvnd1u97MephZPeBBYErQ0pkEXGpm5we/n58CB4EvqfjzSy2kIJBw+AA4UOL2a3efTqhH/Q6hPzKdgGuD5VOA54GdhNoV2wn1rAF+AOSY2W5CO2qvr0wB7r4L+FfgBULfcvcBGyp80T9eWwxcBnQG1gevGxM8/RmwFNhiZtvKeG1FnzMcjh4pVfI2qsTzrwIvE2rnJAF3B3WuIPS7/AOhLYTLgMvc/dBxPr/UQqYL04jUTmY2A3jN3V+IdC1Ss2mLQEQkxikIRERinFpDIiIxTlsEIiIxLuqOE27evLlnZGREugwRkaiyYMGCbe5e5rk0URcEGRkZZGdnR7oMEZGoYma55T2n1pCISIxTEIiIxDgFgYhIjIu6fQQiUvsUFRWxYcMGCgsLI11K1EtKSiItLY3ExMRKv0ZBICIRt2HDBho2bEhGRga6xk3VuTvbt29nw4YNdOjQodKvU2tIRCKusLCQZs2aKQROkpnRrFmzE96yUhCISI2gEKgeVfk9xkwQLN20i//9dBU79x2KdCkiIjVKzATBrFXbePzTlZz18Gf8etpSNuzcf/wXiYjEgJgJgjuGduLDH5/DxWe04rU5uQz9/Qx+8vYilm/ZHenSRCTCCgoK+OMf/3jCr7vkkksoKCg44deNHTuWKVOmnPDrwiVmggCge6sUHhudyef3n8eNgzL4aOkWhj/xBWMnzGPO2u1oEqtIbCovCIqLK74y6gcffEDjxo3DVdYpE5OHj7ZtnMwvL+vB3ed35tXZubz8ZQ7XPjeH3umNuXNoRy7s0Yr4OO24EomEB95byjebqndLvUebFH512enlPv/zn/+cNWvWkJmZSWJiIg0aNKB169YsWrSIb775hiuuuIK8vDwKCwu55557uP3224F/zD7bu3cvF198MWeffTZffvklbdu25c9//jPJycnHrW369On87Gc/4/Dhw/Tr149nnnmGunXr8vOf/5xp06aRkJDARRddxKOPPsrkyZN54IEHiI+Pp1GjRsycObNafj8xGQRHNa5Xhx+d34XbhnRk8oINPD9zLeNeW0jH5vW5bUhHrjqzLXUT4iNdpoiE2cMPP8ySJUtYtGgRM2bM4NJLL2XJkiXHjsV/6aWXaNq0KQcOHKBfv36MGjWKZs2a/dM6Vq1axZtvvsnzzz/P6NGjeeedd7j++oovsV1YWMjYsWOZPn06Xbt25YYbbuCZZ57hhhtuYOrUqSxfvhwzO9Z+evDBB/noo49o27ZtlVpS5YnpIDgqKTGeHwxsz/f6pfPh0i2M/3wN//6nv/PYJyu5eXAHrhvYjpSkyp+lJyJVV9E391Olf//+/3RC1pNPPsnUqVMByMvLY9WqVd8Jgg4dOpCZmQlA3759ycnJOe77rFixgg4dOtC1a1cAbrzxRp5++mnuuusukpKSuPXWW7n00ksZMWIEAIMHD2bs2LGMHj2aq666qjo+KhBj+wiOJyE+jhG92vDeXWfz2i0D6N6qIb/7cDln/fYzfvvBMr7drdPfRWJB/fr1j92fMWMGn376KbNnz2bx4sX06dOnzBO26tate+x+fHw8hw8fPu77lLdfMiEhgXnz5jFq1Cjeffddhg8fDsD48eN56KGHyMvLIzMzk+3bt5/oRyv7/aplLbWMmXF2l+ac3aU5SzbuYvzna3j+i7W89Ld1XNmnLbcP6UTnFg0iXaaIVJOGDRuyZ8+eMp/btWsXTZo0oV69eixfvpw5c+ZU2/t2796dnJwcVq9eTefOnXn11VcZOnQoe/fuZf/+/VxyySUMHDiQzp07A7BmzRoGDBjAgAEDeO+998jLy/vOlklVhC0IzCwJmAnUDd5nirv/qozlRgO/BhxY7O7fD1dNVdGzbSOe+v6ZrN++n+e/WMuk7DwmL9jAhae15I6hnejbvkmkSxSRk9SsWTMGDx5Mz549SU5OpmXLlseeGz58OOPHj6dXr15069aNgQMHVtv7JiUlMWHCBK655ppjO4vHjRvHjh07uPzyyyksLMTdefzxxwG47777WLVqFe7O+eefT+/evauljrBdvN5C5znXd/e9ZpYIzALucfc5JZbpAkwChrn7TjNr4e5bK1pvVlaWR/IKZdv3HmTilzlMnJ3LrgNF9M9oyh1DO3JetxbE6UgjkSpZtmwZp512WqTLqDXK+n2a2QJ3zypr+bDtI/CQvcGPicGtdOrcBjzt7juD11QYAjVBswZ1ufeibnz582H8ckQPNuzczy0Tsxn+vzN5Z8EGioqPRLpEEZETEtadxWYWb2aLgK3AJ+4+t9QiXYGuZvY3M5tjZsPLWc/tZpZtZtn5+fnhLLnS6tdN4OazO/D5/efx2OjeGMZPJy9m6CN/5YUv1rLv4PF3FIlI7fbDH/6QzMzMf7pNmDAh0mV9R9haQ//0JmaNganAj9x9SYnH3weKgNFAGvAF0NPdyz1ANtKtofK4OzNW5DP+8zXMXbeDRsmJ/GBge8YOzqB5g7rHX4FIDFu2bBndu3fXBNJq4O4sX768ZrSGShVWAMwASn/j3wD82d2L3H0dsALocipqqm5mxnndW/D2HYOY+q9nMbBjU56esZrBD3/GL979O7nb90W6RJEaKykpie3bNeblZB29ME1SUtIJvS6cO4tTgSJ3LzCzZOBj4Hfu/n6JZYYD33P3G82sOfAVkOnu5R4cW1O3CMqyJn8vz89cy58WbuTwkSNcfEZr7hzaiZ5tG0W6NJEaRZeqrD7lXaqyoi2CcAZBL2AiEE9oy2OSuz9oZg8C2e4+LTiy6H8IbSkUA//t7m9VtN5oCoKjvt1dyIS/5fD6nFz2HDzM2Z2bc8fQjpzdubk2hUXklIhIEIRLNAbBUbsLi3hj7npemrWOrXsOcnqbFO4Y2olLerYiIV4neYtI+CgIapiDh4t596uNPDtzLWvz99GuaT1uO6cD12Slk5SoIXciUv0UBDXUkSPOJ8u+Zfzna/hqfQHN6tfhxrMyuGFQexrXqxPp8kSkFlEQ1HDuzvycnYz/fA2fLd9KvTrxjOmXzo+GdaFpfQWCiJy8ioJAQ+dqADOjf4em9O/QlBVb9vDszDW8OjuXZZt388atAzW6QkTCSnsoa5hurRry2OhM/uuKnsxZu4PX5+ZGuiQRqeUUBDXUtf3SOadLc377l+Xk7dgf6XJEpBZTENRQZsbDo3oRZ8Z9UxZz5Eh07csRkeihIKjB2jZO5heXnsactTt4TS0iEQkTBUENN+Zoi+iD5azfrhaRiFQ/BUENd7RFFB9n3P+OWkQiUv0UBFFALSIRCScFQZQY0y+dIV1T1SISkWqnIIgSZsbDV51BQpyOIhKR6qUgiCJtGifzixGnMXfdDl6doxaRiFQPBUGUGZ2VztCuqTz8l+W66pmIVAsFQZQxM357rEX0tVpEInLSFARR6GiLaJ5aRCJSDRQEUUotIhGpLgqCKBU60UwtIhE5eQqCKNa6UTL/OaIH89bt4JXZOZEuR0SilIIgyl2Tlca53VL53Ycr1CISkSpREES5Y0cRxatFJCJVoyCoBUq2iCbOzol0OSISZcIWBGaWZGbzzGyxmS01swfKWGasmeWb2aLgdmu46qntrul7tEW0nJxtahGJSOWFc4vgIDDM3XsDmcBwMxtYxnJvu3tmcHshjPXUakdbRInxcdz/jlpEIlJ5YQsCD9kb/JgY3PTXKYzUIhKRqgjrPgIzizezRcBW4BN3n1vGYqPM7Gszm2Jm6eWs53Yzyzaz7Pz8/HCWHPWu6ZvGeWoRicgJCGsQuHuxu2cCaUB/M+tZapH3gAx37wV8CkwsZz3PuXuWu2elpqaGs+SoF2oR9Qq1iHQUkYhUwik5asjdC4AZwPBSj29394PBj88DfU9FPbVdq0ZJ/HJED+bl7ODlL3MiXY6I1HDhPGoo1cwaB/eTgQuA5aWWaV3ix5HAsnDVE2uuDlpEj3ykFpGIVCycWwStgb+a2dfAfEL7CN43swfNbGSwzN3BoaWLgbuBsWGsJ6aoRSQilWXu0fUHIisry7OzsyNdRtSYnJ3HfVO+5pcjenDz2R0iXY6IRIiZLXD3rLKe05nFtdzVfdMY1r0Fj3y0nHVqEYlIGRQEtZyZ8ZsrgxPNdNF7ESmDgiAGtGqUxK8uO535OTuZoKOIRKQUBUGMGHVmW4Z1b8Hv1SISkVIUBDHi6CyiOvFx3Dd5McVqEYlIQEEQQ1qmJPHLy04nO3enTjQTkWMUBDFGLSIRKU1BEGPUIhKR0hQEMahlSugoouzcnUz427pIlyMiEaYgiFFXndmW87u34PcfrWBt/t7jv0BEai0FQYwyM35z1RnUTYjjvilfq0UkEsMUBDGsZUoSvx55OgvUIhKJaQqCGHdlH7WIRGKdgiDGqUUkIgoCUYtIJMYpCAQItYguOC3UIlqjFpFITFEQCPCPcdVJifE60UwkxigI5JgWKUn8emQPFq4v4KVZahGJxAoFgfyTKzLbcsFpLXn0Y7WIRGKFgkD+SahF1FMtIpEYoiCQ71CLSCS2KAikTGoRicQOBYGUSS0ikdgRtiAwsyQzm2dmi81sqZk9UMGyV5uZm1lWuOqRE9ciJYkHRp7OwvUFvDhrbaTLEZEwCecWwUFgmLv3BjKB4WY2sPRCZtYQuBuYG8ZapIouz2zDhT1a8ujHK1m9VS0ikdoobEHgIUf/ciQGt7L6C/8FPAIUhqsWqToz47+v7ElyYjz3T1GLSKQ2Cus+AjOLN7NFwFbgE3efW+r5PkC6u78fzjrk5LRoqBaRSG0W1iBw92J3zwTSgP5m1vPoc2YWBzwO/PR46zGz280s28yy8/Pzw1ewlEstIpHa65QcNeTuBcAMYHiJhxsCPYEZZpYDDASmlbXD2N2fc/csd89KTU09BRVLaUdbRPXqxHOfWkQitUo4jxpKNbPGwf1k4AJg+dHn3X2Xuzd39wx3zwDmACPdPTtcNcnJOdoi+mp9AS98oRaRSG0Rzi2C1sBfzexrYD6hfQTvm9mDZjYyjO8rYTSydxsu6tGS//lkJau37ol0OSJSDcw9ujbxs7KyPDtbGw2RtHVPIRc9PpOMZvV5586ziI+zSJckIsdhZgvcvcxztXRmsZywoy2iRXlqEYnUBgoCqRK1iERqDwWBVImZ8VBwFNHPJuui9yLRTEEgVVayRfS8WkQiUUtBICdlZO82/MvpLXn0oxW8t3hTpMsRkSpQEMhJMTN+f01v+rRrzN1vfcUbc9dHuiQROUEKAjlpKUmJvHLzAM7tmsp/TP07f5yxmmg7LFkklikIpFok14nnuRuyuDyzDY98uIKH/7JcYSASJRIiXYDUHonxcTw+OpNGyYk8O3MtBfuL+M1VZ+iEM5EaTkEg1Souznhg5Ok0Tk7kyc9Ws7uwiCeuzaRuQnykSxORclSqNWRmncysbnD/XDO7++hAOZHSzIx7L+rGf47owV+WbOGWl7PZd/BwpMsSkXJUdh/BO0CxmXUGXgQ6AG+ErSqpFW45uwOPXtOb2Wu3c90LcynYfyjSJYlIGSobBEfc/TBwJfCEu/+E0HRRkQpd3TeNZ647k28272b0s7P5dreuSCpS01Q2CIrM7HvAjcDRy0omhqckqW0uOr0VL9/Uj407DzDqmS/J2bYv0iWJSAmVDYKbgEHAf7v7OjPrALwWvrKktjmrU3PeuG0g+w4e5urxs1m2eXekSxKRQKWCwN2/cfe73f1NM2sCNHT3h8Ncm9QyvdMbM3ncIBLijDHPzmZB7o5IlyQiVP6ooRlmlmJmTYHFwAQzeyy8pUlt1LlFQ6bcOYhmDepy3QtzmbFia6RLEol5lW0NNXL33cBVwAR370voGsQiJyytST0mjxtEx+YNuO2VbA2rE4mwygZBgpm1Bkbzj53FIlXWvEFd3rpjIH3Sm3D3W1/x+tzcSJckErMqGwQPAh8Ba9x9vpl1BFaFryyJBSlJiUy8uT/ndWvB/5u6RMPqRCKksjuLJ7t7L3e/M/h5rbuPCm9pEguS68Tz7A/6HhtW91sNqxM55So1a8jM0oA/AIMBB2YB97j7hjDWJjGi5LC652aupWD/IX5z5RkkxGs4rsipUNn/p00ApgFtgLbAe8FjItXi6LC6u4d1ZlL2Bu564ysOHi6OdFkiMaGyQZDq7hPc/XBwexlIDWNdEoNKDqv7cKmG1YmcKpUNgm1mdr2ZxQe364HtFb3AzJLMbJ6ZLTazpWb2QBnLjDOzv5vZIjObZWY9qvIhpHa55ewO/E+JYXU792lYnUg4VTYIbiZ06OgWYDNwNaGxExU5CAxz995AJjDczAaWWuYNdz/D3TOBRwCdpCYAjCo1rG7LLg2rEwmXyh41tN7dR7p7qru3cPcrCJ1cVtFr3N33Bj8mBjcvtUzJgTP1Sz8vse3osLpNBQe4eryG1YmEy8kclnHv8RYI2kiLgK3AJ+4+t4xlfmhmawhtEdxdznpuN7NsM8vOz88/iZIl2pzVqTlv3q5hdSLhdDJBcNwL0bp7cdD2SQP6m1nPMpZ52t07Af8G/KKc9Tzn7lnunpWaqn3UsaZXWmhYXWK8MfrZ2WTnaFidSHU6mSCodBvH3QuAGcDwChZ7C7jiJOqRWqxzi4ZMHjeI5g3qcv2LGlYnUp0qDAIz22Nmu8u47SF0TkFFr009el1jM0smNKRueallupT48VI0tkIqUHJY3a0TNaxOpLpUeGaxuzc8iXW3BiaaWTyhwJnk7u+b2YNAtrtPA+4yswuAImAnoSugiZTr6LC6W1/O5u63vmJ3YRHXDWgf6bJEoppF21yXrKwsz87OjnQZEmGFRcX88PWFTF++lfv+pRv/em4nzI6720okZpnZAnfPKus5DXORqJSUGM/4H/Tlisw2/P4jDasTORmVGjonUhMlxsfxmIbViZw0BYFEtbg449cjT6dRvTo8OX0Vuw8c5n+/l0ndhPhIlyYSNfTVSaKemXHvhV35ZTCs7uaX57NXw+pEKk1BILXGzcGwujlrd2hYncgJUBBIrTKqbxrjr+/LMg2rE6k0BYHUOhf2aMnEm/qzeVehhtWJVIKCQGqlQZ2a8eZtA9l/qJirx8/mm00aVidSHgWB1FpnpDVi0h2hYXVjntOwOpHyKAikVuvcogFT7jyLVA2rEymXgkBqvbaNk5k0bhCdUkPD6qZpWJ3IP1EQSExo3qAub94+kDPbN+Get77iofe/Yfveg5EuS6RGUBBIzEhJSuSVm/tzTd80XvrbOoY88lce/WgFu/YXRbo0kYjS9FGJSau37uWJT1fy/tebaZiUwG3ndOSmwRk0TEqMdGkiYVHR9FEFgcS0ZZt38/gnK/n4m29pXC+RcUM7ccOg9tSrozFcUrsoCESO4+sNBTz2yUpmrMineYO6/Ou5nfj+gHYkJWp4ndQOCgKRSlqQu4P/+XglX67ZTquUJO4a1pnRWenUSdDuNIluCgKRE/Tlmm089vFKsnN3ktYkmbvP78JVfdrqWgcStXSFMpETdFan5kweN4iXb+pH0/p1uH/K11z4+Ez+vGgjxUei68uTyPEoCETKYWac260Ff/7hYJ77QV/qJsRxz1uLGP7ETP7y980cUSBILaEgEDkOM+Oi01vxwd3n8NT3+3DEnTtfX8iIP8xi+rJvda1kiXoKApFKioszRvRqw8c/Gcpjo3uz79BhbpmYzZV//JKZK/MVCBK1tLNYpIqKio/wp4UbeHL6ajYWHKB/RlN+elFXBnRsFunSRL4jIjuLzSzJzOaZ2WIzW2pmD5SxzL1m9o2ZfW1m082sfbjqEaluifFxjOnXjs9+NpQHLz+dnO37GPPcHK5/YS4L1++MdHkilRa2LQIzM6C+u+81s0RgFnCPu88pscx5wFx3329mdwLnuvuYitarLQKpqQqLinltTi7PzFjD9n2HGNa9Bfde2JWebRtFujSRyGwReMje4MfE4Oallvmru+8PfpwDpIWrHpFwS0qM59ZzOjLz/vO471+6sSB3JyP+MItxry5gxZY9kS5PpFxh3UdgZvHAAqAz8LS7/1sFyz4FbHH3h8p47nbgdoB27dr1zc3NDVPFItVnd2ERL36xjpdmrWPvocNc1qsNP76gCx1TG0S6NIlBET+z2MwaA1OBH7n7kjKevx64Cxjq7hUOiVdrSKJNwf5DPDdzLRP+lsPBw8VcdWYa95zfhfSm9SJdmsSQiAdBUMSvgH3u/mipxy8A/kAoBI57HUEFgUSrbXsPMn7GGl6dk0vxEWd0v3TuOq8zbRonR7o0iQGROmooNdgSwMySgQuA5aWW6QM8C4ysTAiIRLPmDeryixE9mHn/eXx/QDsmZ+dx7u9n8OtpS9m6uzDS5UkMC+dRQ72AiUA8ocCZ5O4PmtmDQLa7TzOzT4EzgM3By9a7+8iK1qstAqktNuzcz1OfrWbygg0kxhs3DsrgjqGdaFq/TqRLk1qoRrSGqouCQGqbnG37eHL6KqYu2ki9xHhuGtyB287pSKN6ulqaVB8FgUgUWL11D49/uor/0+UzJQwUBCJR5JtNu3n805V88s23NKmXyK3ndGR0VjqpDetGujSJYgoCkSi0OC90+czPV+aTEGcM696Ca/unM6RLqi6QIydMQSASxVZv3cvk7DzeWbiBbXsP0TKlLlf3TWN0Vjrtm9WPdHkSJRQEIrVAUfERpi/byqTsPGas2MoRh4Edm3Jtv3YM79mKpMT4SJcoNZiCQKSW2bKrkHcWbuDt+Xms37GflKQELs9sy5h+6RpyJ2VSEIjUUkeOOHPWbWfS/Dz+smQLBw8foUfrFK7tn87lvdvqEFQ5RkEgEgN27S/iz4s38vb8PJZu2k2dhDgu7tmKMVnpDOzYjLg4i3SJEkEKApEYs2TjLiZl5/HuVxvZXXiYdk3rMTorjav7ptOqUVKky5MIUBCIxKjComI+XLKFt+fnMXvtduIMhnZNZUy/dIZ1b0mdBB2GGisUBCJC7vZ9TM7ewOQFeXy7+yDN6tdhVHAYaucWukZCbacgEJFjDhcfYeaqfN6en8f0ZVs5fMTp274JY7LSubRXa+rXTYh0iRIGCgIRKVP+noNM/WoDb83PY23+PurXieey3m0Y3S+dPumNCV16XGoDBYGIVMjdWZC7k7fn5/H+15s5UFRMlxYNGNMvnSv7tKVZA805inYKAhGptL0HD/P+4k28NT+PRXkFJMYbF/ZoyeisdM7pkkq8DkONSgoCEamSld/u4e35eUz9aiM79h2iTaMkru6bxjVZ6brmcpRREIjISTl0+AifLvuWt+bn8cWqfAAGd2rO6H7pXNSjpeYcRQEFgYhUm40FB5iSvYFJ2XlsLDhAo+REruwTmnN0WuuUSJcn5VAQiEi1O3LE+duabbw9P4+Pl37LoeIj9EprxLDuLeiX0ZTM9MY6FLUGqSgI9L+SiFRJXJxxTpdUzumSys59h3h30Ub+tHAj/zt9Fe4QH2f0aJ1CVkYTsto3pV9GE1qkaLxFTaQtAhGpVrsLi/hqfQHZOTuYn7ODRXkFFBYdAaBd03pktW9CVkYoGDqlNtAwvFNEWwQicsqkJCUytGsqQxAdA8AAAAu0SURBVLumAqEL6izdtPtYMMxclc+fvtoIQKPkxGPBkJXRhDPaNtKO5wjQFoGInFLuTs72/czP2cGCnJ3Mz93B2vx9ANSJj6NXWiP6ZjShX/um9G3fhCb160S44tohIjuLzSwJmAnUJbTlMcXdf1VqmSHAE0Av4Fp3n3K89SoIRGqf7XsPsiB3J9m5O5mfs4MlG3dRVBz629S5RQP6BfsZsjKa0K5pPY2+qIJIBYEB9d19r5klArOAe9x9TollMoAU4GfANAWBiEBofPbivAKyc3eSnbOD7Nyd7Ck8DEBqw7r0y2hC32AHdI/WKSTEa5z28URkH4GHEmZv8GNicPNSy+QEBR4JVx0iEn2SEuMZ0LEZAzo2A0KHqq7cuofsnJ3BvoadfPD3LQDUqxNPZnrjYzug+7RrQgMdtnpCwvrbMrN4YAHQGXja3edWcT23A7cDtGvXrvoKFJGoEBdndG+VQvdWKVw/sD0Am3cdOBYM2bk7eeqzVRxxiDM4rXUK/TJC+xj6ZTTVVdmO45TsLDazxsBU4EfuvqSM518G3ldrSESqas/Rw1aDdtJX6ws4UFQMQFqT5BKHrTalS4vYO2w14oePunuBmc0AhgPfCQIRkZPVMCmRIV1TGVLisNVlm3czP9hqmLV6O+8u2gRASlICfds3YUjXVK7t147kOrF9yGrYgsDMUoGiIASSgQuA34Xr/URESkqMj6NXWmN6pTXmlrM74O6s37Gf+Tk7WZC7g3nrdvDAe9/wzIw1/GhYZ8b0axez13AO51FDvYCJQDwQB0xy9wfN7EEg292nmVk/Qi2jJkAhsMXdT69ovWoNiUh1mbt2O49+vIL5OTtJa5LMTy7oyhV92tbKay5o6JyISDncnc9X5vP7j1awdNNuOrdowE8v7Mrwnq1q1fkKFQVBbG4HiYgEzIxzu7XgvbvO5o/XnYm7c+frCxn51N+YsWIr0fZluSoUBCIihA5RveSM1nz8k6E8ek1vdu4/xNgJ8xnz7BzmrdsR6fLCSq0hEZEyHDp8hLfnr+fJz1aTv+cgQ7um8rOLunFGWqNIl1Yl2kcgIlJFBw4V88rsHJ75fA0F+4u4uGcr7r2wK11aNox0aSdEQSAicpJ2FxbxwhfrePGLtRwoKubKPmn8+IIupDetF+nSKkVBICJSTXbsO8QzM1bzyuxcjrhzbb923DWsMy1r+NXXFAQiItVsy65C/vDZKt6en0d8nDH2rAzGDe1UY6+foCAQEQmT9dv388SnK5m6aCP16yRw6zkduOXsDjRMSox0af9EQSAiEmYrv93DYx+v5MOlW2hSL5E7z+3EDYMyasylNxUEIiKnyOK8Ah79eAVfrNpGy5S63DWsC2Oy0iM+x0hBICJyis1Zu51HP1pBdu5O0puG5hhdnhm5OUYaMSEicooN7NiMyeMGMeGmfqQkJXLvpMUMf2ImHy7ZXOPGVigIRETCxMw4L5hj9PT3z+SIO+NeC80x+nxlfo0JBAWBiEiYxcUZl/ZqzUc/HsLvr+7Fjn2HuPGleYx5bg7zcyI/x0j7CERETrGDh4t5e34efwjmGJ3bLTTHqGfb8M0x0s5iEZEa6MChYibOzuGZGWvYdaCIS84IzTHq3KL65xgpCEREarDdhUW8MHMtL85ax4GiYq46M417zq/eOUYKAhGRKLB970GembGGV+bk4u58r3877jqvMy2qYY6RgkBEJIps3nWAP3y2mknz80iIN248K4NxQ05ujpHOIxARiSKtGyXzmyvPYPpPh3Jxz9Y8N3MtQx75K9MWbwrL+ykIRERqqPbN6vP4mEw+vGcIZ3VuRkaz8Fz7ICEsaxURkWrTrVVDnv1BmV2daqEtAhGRGKcgEBGJcWELAjNLMrN5ZrbYzJaa2QNlLFPXzN42s9VmNtfMMsJVj4iIlC2cWwQHgWHu3hvIBIab2cBSy9wC7HT3zsDjwO/CWI+IiJQhbEHgIXuDHxODW+mTFi4HJgb3pwDnm1lkhnWLiMSosO4jMLN4M1sEbAU+cfe5pRZpC+QBuPthYBfQrIz13G5m2WaWnZ+fH86SRURiTliDwN2L3T0TSAP6m1nPUouU9e3/O6c6u/tz7p7l7lmpqanhKFVEJGadkqOG3L0AmAEML/XUBiAdwMwSgEZA5Idzi4jEkLCdUGZmqUCRuxeYWTJwAd/dGTwNuBGYDVwNfObHGX60YMGCbWaWW8WymgPbqvjaSIimeqOpVoiueqOpVoiueqOpVji5etuX90Q4zyxuDUw0s3hCWx6T3P19M3sQyHb3acCLwKtmtprQlsC1x1upu1e5N2Rm2eUNXaqJoqneaKoVoqveaKoVoqveaKoVwldv2ILA3b8G+pTx+C9L3C8ErglXDSIicnw6s1hEJMbFWhA8F+kCTlA01RtNtUJ01RtNtUJ01RtNtUKY6o26C9OIiEj1irUtAhERKUVBICIS42ImCMxsuJmtCCad/jzS9VTEzF4ys61mtiTStRyPmaWb2V/NbFkwZfaeSNdUnspMxK2JglEtX5nZ+5GupSJmlmNmfzezRWZW4y8sbmaNzWyKmS0P/vsdFOmaymJm3YLf6dHbbjP7cbW+RyzsIwjOZVgJXEjobOb5wPfc/ZuIFlYOMxsC7AVecffSYzlqFDNrDbR294Vm1hBYAFxRE3+3wUDD+u6+18wSgVnAPe4+J8KlVcjM7gWygBR3HxHpespjZjlAlrtHxQlaZjYR+MLdXzCzOkC9YApCjRX8LdsIDHD3qp5Y+x2xskXQH1jt7mvd/RDwFqHJpzWSu88kSkZtuPtmd18Y3N8DLCM0TLDGqeRE3BrFzNKAS4EXIl1LbWJmKcAQQie14u6HanoIBM4H1lRnCEDsBMGxKaeBDdTQP1bRLLiwUB+g9JTZGqMSE3FrmieA+4EjkS6kEhz42MwWmNntkS7mODoC+cCEoO32gpnVj3RRlXAt8GZ1rzRWgqBSU06l6sysAfAO8GN33x3pespTiYm4NYaZjQC2uvuCSNdSSYPd/UzgYuCHQYuzpkoAzgSecfc+wD6gpu87rAOMBCZX97pjJQiOTTkNpAGbIlRLrRP0298BXnf3P0W6nsqoYCJuTTIYGBn03t8ChpnZa5EtqXzuvin4dyswlVBLtqbaAGwosUU4hVAw1GQXAwvd/dvqXnGsBMF8oIuZdQhS9VpCk0/lJAU7YF8Elrn7Y5GupyJmlmpmjYP7RyfiLo9sVeVz93939zR3zyD03+xn7n59hMsqk5nVDw4WIGixXATU2KPe3H0LkGdm3YKHzgdq3AEOpXyPMLSFILzTR2sMdz9sZncBHwHxwEvuvjTCZZXLzN4EzgWam9kG4Ffu/mJkqyrXYOAHwN+D3jvAf7j7BxGsqTxlTsSNcE21RUtganCl2QTgDXf/MLIlHdePgNeDL4drgZsiXE+5zKweoaMe7wjL+mPh8FERESlfrLSGRESkHAoCEZEYpyAQEYlxCgIRkRinIBARiXEKApFSzKy41LTHajvj1MwyomGqrMSWmDiPQOQEHQjGUIjEBG0RiFRSMG//d8E1DeaZWefg8fZmNt3Mvg7+bRc83tLMpgbXP1hsZmcFq4o3s+eDayJ8HJzlLBIxCgKR70ou1RoaU+K53e7eH3iK0GRQgvuvuHsv4HXgyeDxJ4HP3b03oTk2R89m7wI87e6nAwXAqDB/HpEK6cxikVLMbK+7Nyjj8RxgmLuvDQbtbXH3Zma2jdDFeYqCxze7e3MzywfS3P1giXVkEBp/3SX4+d+ARHd/KPyfTKRs2iIQOTFezv3ylinLwRL3i9G+OokwBYHIiRlT4t/Zwf0vCU0HBbiO0CUwAaYDd8KxC+KknKoiRU6EvomIfFdyiUmqAB+6+9FDSOua2VxCX6K+Fzx2N/CSmd1H6KpXR6dY3gM8Z2a3EPrmfyewOezVi5wg7SMQqaRouzi7SGWpNSQiEuO0RSAiEuO0RSAiEuMUBCIiMU5BICIS4xQEIiIxTkEgIhLj/j92yS8ErhM5FgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_function_epoch = L_list\n",
    "#loss_function_epoch_val = DNN.L_list_val\n",
    "plt.title('Loss function - Epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.plot(loss_function_epoch, label='train_loss')#, color='b'\n",
    "#plt.plot(loss_function_epoch_val, label='val_loss')# color='b'\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題9】出力サイズとパラメータ数の計算  \n",
    ">CNNモデルを構築する際には、全結合層に入力する段階で特徴量がいくつになっているかを事前に計算する必要があります。\n",
    ">\n",
    ">また、巨大なモデルを扱うようになると、メモリや計算速度の関係でパラメータ数の計算は必須になってきます。フレームワークでは各層のパラメータ数を表示させることが可能ですが、意味を理解していなくては適切な調整が行えません。\n",
    ">\n",
    ">以下の3つの畳み込み層の出力サイズとパラメータ数を計算してください。パラメータ数についてはバイアス項も考えてください。\n",
    ">\n",
    ">1  \n",
    ">\n",
    ">- 入力サイズ : 144×144, 3チャンネル\n",
    ">- フィルタサイズ : 3×3, 6チャンネル\n",
    ">- ストライド : 1\n",
    ">- パディング : なし\n",
    ">\n",
    ">2 \n",
    ">\n",
    ">- 入力サイズ : 60×60, 24チャンネル\n",
    ">- フィルタサイズ : 3×3, 48チャンネル\n",
    ">- ストライド　: 1\n",
    ">- パディング : なし\n",
    ">\n",
    ">3\n",
    ">\n",
    ">- 入力サイズ : 20×20, 10チャンネル\n",
    ">- フィルタサイズ: 3×3, 20チャンネル\n",
    ">- ストライド : 2\n",
    ">- パディング : なし\n",
    ">\n",
    ">＊最後の例は丁度良く畳み込みをすることができない場合です。  \n",
    ">フレームワークでは余ったピクセルを見ないという処理が行われることがあるので、その場合を考えて計算してください。  \n",
    ">端が欠けてしまうので、こういった設定は好ましくないという例です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1  \n",
    "- 出力サイズ : 142×6\n",
    "- パラメータ数 : 124416\n",
    "- バイアス項 : 6\n",
    "\n",
    "2  \n",
    "- 出力サイズ : 37×48\n",
    "- パラメータ数 : 172800\n",
    "- バイアス項 : 48\n",
    "\n",
    "3  \n",
    "- 出力サイズ : 9×20\n",
    "- パラメータ数 : 8000\n",
    "- バイアス項 : 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
